{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omkar.karve\\AppData\\Roaming\\Python\\Python37\\site-packages\\requests\\__init__.py:80: RequestsDependencyWarning: urllib3 (1.26.2) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.compat.v1 import InteractiveSession # This is needed to run on Windows 10 laptop with Cuda\n",
    "# This is needed to run on Windows 10 laptop with Cuda\n",
    "print(tf.__version__)\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU name: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence modelling \n",
    "\n",
    "## Coding tutorials\n",
    " #### [1.  The IMDb dataset](#coding_tutorial_1)\n",
    " #### [2. Padding and masking sequence data](#coding_tutorial_2)\n",
    " #### [3. The Embedding layer](#coding_tutorial_3)\n",
    " #### [4. The Embedding Projector](#coding_tutorial_4)\n",
    " #### [5. Recurrent neural network layers](#coding_tutorial_5)\n",
    " #### [6. Stacked RNNs and the Bidirectional wrapper](#coding_tutorial_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_1\"></a>\n",
    "## The IMDb Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the IMDB review sentiment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import imdb\n",
    "\n",
    "import tensorflow.keras.datasets.imdb as imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Download and assign the data set using load_data()\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = imdb.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the type of the data\n",
    "\n",
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the shape of the data\n",
    "x_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 22665,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 21631,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 19193,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 10311,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 31050,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 12118,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first dataset element input\n",
    "# Notice encoding\n",
    "x_train[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first dataset element output\n",
    "y_train[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset with different options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
       "         list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 36893, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 25249, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 46151, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
       "         list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 44076, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 51428, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
       "         ...,\n",
       "         list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 86527, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 14532, 325, 725, 134, 15271, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 11656, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 26094, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 17793, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 14492, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 17793, 5, 27, 710, 117, 74936, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 17793, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 17793, 7750, 5, 4241, 18, 4, 8497, 13164, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 11027, 4, 3586, 22459]),\n",
       "         list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 21469, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 40691, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 29455, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 11418, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 21213, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
       "         list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 12815, 270, 14437, 5, 16923, 12255, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 16553, 21, 27, 9685, 6139, 5, 29043, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 85010, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 70907, 10755, 544, 5, 383, 1271, 848, 1468, 12183, 497, 16876, 8, 1597, 8778, 19280, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
       "        dtype=object),\n",
       "  array([1, 0, 0, ..., 0, 1, 0], dtype=int64)),\n",
       " (array([list([1, 591, 202, 14, 31, 6, 717, 10, 10, 18142, 10698, 5, 4, 360, 7, 4, 177, 5760, 394, 354, 4, 123, 9, 1035, 1035, 1035, 10, 10, 13, 92, 124, 89, 488, 7944, 100, 28, 1668, 14, 31, 23, 27, 7479, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 15387, 38, 32, 25, 7944, 451, 202, 14, 6, 717]),\n",
       "         list([1, 14, 22, 3443, 6, 176, 7, 5063, 88, 12, 2679, 23, 1310, 5, 109, 943, 4, 114, 9, 55, 606, 5, 111, 7, 4, 139, 193, 273, 23, 4, 172, 270, 11, 7216, 10626, 4, 8463, 2801, 109, 1603, 21, 4, 22, 3861, 8, 6, 1193, 1330, 10, 10, 4, 105, 987, 35, 841, 16873, 19, 861, 1074, 5, 1987, 17975, 45, 55, 221, 15, 670, 5304, 526, 14, 1069, 4, 405, 5, 2438, 7, 27, 85, 108, 131, 4, 5045, 5304, 3884, 405, 9, 3523, 133, 5, 50, 13, 104, 51, 66, 166, 14, 22, 157, 9, 4, 530, 239, 34, 8463, 2801, 45, 407, 31, 7, 41, 3778, 105, 21, 59, 299, 12, 38, 950, 5, 4521, 15, 45, 629, 488, 2733, 127, 6, 52, 292, 17, 4, 6936, 185, 132, 1988, 5304, 1799, 488, 2693, 47, 6, 392, 173, 4, 21686, 4378, 270, 2352, 4, 1500, 7, 4, 65, 55, 73, 11, 346, 14, 20, 9, 6, 976, 2078, 7, 5293, 861, 12746, 5, 4182, 30, 3127, 23651, 56, 4, 841, 5, 990, 692, 8, 4, 1669, 398, 229, 10, 10, 13, 2822, 670, 5304, 14, 9, 31, 7, 27, 111, 108, 15, 2033, 19, 7836, 1429, 875, 551, 14, 22, 9, 1193, 21, 45, 4829, 5, 45, 252, 8, 12508, 6, 565, 921, 3639, 39, 4, 529, 48, 25, 181, 8, 67, 35, 1732, 22, 49, 238, 60, 135, 1162, 14, 9, 290, 4, 58, 10, 10, 472, 45, 55, 878, 8, 169, 11, 374, 5687, 25, 203, 28, 8, 818, 12, 125, 4, 3077]),\n",
       "         list([1, 111, 748, 4368, 1133, 33782, 24563, 4, 87, 1551, 1262, 7, 31, 318, 9459, 7, 4, 498, 5076, 748, 63, 29, 5161, 220, 686, 10941, 5, 17, 12, 575, 220, 2507, 17, 6, 185, 132, 24563, 16, 53, 928, 11, 51278, 74, 4, 438, 21, 27, 10044, 589, 8, 22, 107, 20123, 19550, 997, 1638, 8, 35, 2076, 9019, 11, 22, 231, 54, 29, 1706, 29, 100, 18995, 2425, 34, 12998, 8738, 48078, 5, 19353, 98, 31, 2122, 33, 6, 58, 14, 3808, 1638, 8, 4, 365, 7, 2789, 3761, 356, 346, 4, 27608, 1060, 63, 29, 93, 11, 5421, 11, 15236, 33, 6, 58, 54, 1270, 431, 748, 7, 32, 2580, 16, 11, 94, 19469, 10, 10, 4, 993, 45222, 7, 4, 1766, 2634, 2164, 24563, 8, 847, 8, 1450, 121, 31, 7, 27, 86, 2663, 10760, 16, 6, 465, 993, 2006, 30995, 573, 17, 61862, 42, 4, 17345, 37, 473, 6, 711, 6, 8869, 7, 328, 212, 70, 30, 258, 11, 220, 32, 7, 108, 21, 133, 12, 9, 55, 465, 849, 3711, 53, 33, 2071, 1969, 37, 70, 1144, 4, 5940, 1409, 74, 476, 37, 62, 91, 1329, 169, 4, 1330, 10104, 146, 655, 2212, 5, 258, 12, 184, 10104, 546, 5, 849, 10333, 7, 4, 22, 1436, 18, 631, 1386, 797, 7, 4, 8712, 71, 348, 425, 4320, 1061, 19, 10288, 5, 12141, 11, 661, 8, 339, 17863, 4, 2455, 11434, 7, 4, 1962, 10, 10, 263, 787, 9, 270, 11, 6, 9466, 4, 61862, 48414, 121, 4, 5437, 26, 4434, 19, 68, 1372, 5, 28, 446, 6, 318, 7149, 8, 67, 51, 36, 70, 81, 8, 4392, 2294, 36, 1197, 8, 68411, 25399, 18, 6, 711, 4, 9909, 26, 10296, 1125, 11, 14, 636, 720, 12, 426, 28, 77, 776, 8, 97, 38, 111, 7489, 6175, 168, 1239, 5189, 137, 25399, 18, 27, 173, 9, 2399, 17, 6, 12397, 428, 14657, 232, 11, 4, 8014, 37, 272, 40, 2708, 247, 30, 656, 6, 13182, 54, 25399, 3292, 98, 6, 2840, 40, 558, 37, 6093, 98, 4, 17345, 1197, 15, 14, 9, 57, 4893, 5, 4659, 6, 275, 711, 7937, 25399, 3292, 98, 6, 31036, 10, 10, 6639, 19, 14, 10241, 267, 162, 711, 37, 5900, 752, 98, 4, 17345, 2378, 90, 19, 6, 73284, 7, 36744, 1810, 77553, 4, 4770, 3183, 930, 8, 508, 90, 4, 1317, 8, 4, 48414, 17, 15454, 3965, 1853, 4, 1494, 8, 4468, 189, 4, 31036, 6287, 5774, 4, 4770, 5, 95, 271, 23, 6, 7742, 6063, 21627, 5437, 33, 1526, 6, 425, 3155, 33697, 4535, 1636, 7, 4, 4669, 11966, 469, 4, 4552, 54, 4, 150, 5664, 17345, 280, 53, 68411, 25399, 18, 339, 29, 1978, 27, 7885, 5, 17303, 68, 1830, 19, 6571, 14605, 4, 1515, 7, 263, 65, 2132, 34, 6, 5680, 7489, 43, 159, 29, 9, 4706, 9, 387, 73, 195, 584, 10, 10, 1069, 4, 58, 810, 54, 14, 6078, 117, 22, 16, 93, 5, 1069, 4, 192, 15, 12, 16, 93, 34, 6, 1766, 28228, 33, 4, 5673, 7, 15, 18760, 9252, 3286, 325, 12, 62, 30, 776, 8, 67, 14, 17, 6, 12214, 44, 148, 687, 24563, 203, 42, 203, 24, 28, 69, 32157, 6676, 11, 330, 54, 29, 93, 61862, 21, 845, 14148, 27, 1099, 7, 819, 4, 22, 1407, 17, 6, 14967, 787, 7, 2460, 19569, 61862, 100, 30, 4, 3737, 3617, 3169, 2321, 42, 1898, 11, 4, 3814, 42, 101, 704, 7, 101, 999, 15, 1625, 94, 2926, 180, 5, 9, 9101, 34, 15205, 45, 6, 1429, 22, 60, 6, 1220, 31, 11, 94, 6408, 96, 21, 94, 749, 9, 57, 975]),\n",
       "         ...,\n",
       "         list([1, 13, 1408, 15, 8, 135, 14, 9, 35, 32, 46, 394, 20, 62, 30, 5093, 21, 45, 184, 78, 4, 1492, 910, 769, 2290, 2515, 395, 4257, 5, 1454, 11, 119, 16946, 89, 1036, 4, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 7, 185, 2280, 284, 1842, 60664, 37, 315, 4, 226, 20, 272, 2942, 40, 29, 152, 60, 181, 8, 30, 50, 553, 362, 80, 119, 12, 21, 846, 5518]),\n",
       "         list([1, 11, 119, 241, 9, 4, 840, 20, 12, 468, 15, 94, 3684, 562, 791, 39, 4, 86, 107, 8, 97, 14, 31, 33, 4, 2960, 7, 743, 46, 1028, 9, 3531, 5, 4, 768, 47, 8, 79, 90, 145, 164, 162, 50, 6, 501, 119, 7, 9, 4, 78, 232, 15, 16, 224, 11, 4, 333, 20, 4, 985, 200, 5, 28739, 5, 9, 1861, 8, 79, 357, 4, 20, 47, 220, 57, 206, 139, 11, 12, 5, 55, 117, 212, 13, 1276, 92, 124, 51, 45, 1188, 71, 536, 13, 520, 14, 20, 6, 2302, 7, 470]),\n",
       "         list([1, 6, 52, 7465, 430, 22, 9, 220, 2594, 8, 28, 24357, 519, 3227, 6, 769, 15, 47, 6, 3482, 4067, 8, 114, 5, 33, 222, 31, 55, 184, 704, 5586, 18020, 19, 346, 3153, 5, 6, 364, 350, 4, 184, 5586, 9, 133, 1810, 11, 5417, 13226, 21, 4, 7298, 42657, 570, 50, 2005, 2643, 9, 6, 1249, 17, 6, 25194, 27803, 21, 17, 6, 1211, 232, 1138, 2249, 29, 266, 56, 96, 346, 194, 308, 9, 194, 21, 29, 218, 1078, 19, 4, 78, 173, 7, 27, 20067, 5698, 3406, 718, 21264, 9, 6, 6907, 17, 210, 5, 3281, 5677, 47, 77, 395, 14, 172, 173, 18, 2740, 2931, 4517, 82, 127, 27, 173, 11, 6, 392, 217, 21, 50, 9, 57, 65, 12, 14274, 53, 40, 35, 390, 7, 11, 4, 3567, 7, 4, 314, 74, 6, 792, 22, 16261, 19, 714, 727, 5205, 382, 4, 91, 6533, 439, 19, 14, 20, 9, 1441, 5805, 1118, 4, 756, 25, 124, 4, 31, 12, 16, 93, 804, 34, 2005, 2643])],\n",
       "        dtype=object),\n",
       "  array([0, 1, 1, ..., 0, 0, 0], dtype=int64)))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset with defaults\n",
    "\n",
    "imdb.load_data(path='imdb.npz',\n",
    "              index_from=3)\n",
    "# ~/.keras/dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([list([1, 14, 22, 16, 43, 530, 973, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 2, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]),\n",
       "         list([1, 194, 2, 194, 2, 78, 228, 5, 6, 2, 2, 2, 134, 26, 4, 715, 8, 118, 2, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 2, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2, 2, 5, 647, 4, 116, 9, 35, 2, 4, 229, 9, 340, 2, 4, 118, 9, 4, 130, 2, 19, 4, 2, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 2, 2, 398, 4, 2, 26, 2, 5, 163, 11, 2, 2, 4, 2, 9, 194, 775, 7, 2, 2, 349, 2, 148, 605, 2, 2, 15, 123, 125, 68, 2, 2, 15, 349, 165, 2, 98, 5, 4, 228, 9, 43, 2, 2, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 2, 228, 2, 5, 2, 656, 245, 2, 5, 4, 2, 131, 152, 491, 18, 2, 32, 2, 2, 14, 9, 6, 371, 78, 22, 625, 64, 2, 9, 8, 168, 145, 23, 4, 2, 15, 16, 4, 2, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
       "         list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 2, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2, 311, 12, 16, 2, 33, 75, 43, 2, 296, 4, 86, 320, 35, 534, 19, 263, 2, 2, 4, 2, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 2, 43, 645, 662, 8, 257, 85, 2, 42, 2, 2, 83, 68, 2, 15, 36, 165, 2, 278, 36, 69, 2, 780, 8, 106, 14, 2, 2, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2, 51, 9, 170, 23, 595, 116, 595, 2, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
       "         ...,\n",
       "         list([1, 11, 6, 230, 245, 2, 9, 6, 2, 446, 2, 45, 2, 84, 2, 2, 21, 4, 912, 84, 2, 325, 725, 134, 2, 2, 84, 5, 36, 28, 57, 2, 21, 8, 140, 8, 703, 5, 2, 84, 56, 18, 2, 14, 9, 31, 7, 4, 2, 2, 2, 2, 2, 18, 6, 20, 207, 110, 563, 12, 8, 2, 2, 8, 97, 6, 20, 53, 2, 74, 4, 460, 364, 2, 29, 270, 11, 960, 108, 45, 40, 29, 2, 395, 11, 6, 2, 500, 7, 2, 89, 364, 70, 29, 140, 4, 64, 2, 11, 4, 2, 26, 178, 4, 529, 443, 2, 5, 27, 710, 117, 2, 2, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 2, 2, 10, 10, 288, 2, 2, 34, 2, 2, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2, 234, 2, 2, 7, 496, 4, 139, 929, 2, 2, 2, 5, 2, 18, 4, 2, 2, 250, 11, 2, 2, 4, 2, 2, 747, 2, 372, 2, 2, 541, 2, 7, 4, 59, 2, 4, 2, 2]),\n",
       "         list([1, 2, 2, 69, 72, 2, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 2, 2, 45, 58, 2, 13, 197, 12, 16, 43, 23, 2, 5, 62, 30, 145, 402, 11, 2, 51, 575, 32, 61, 369, 71, 66, 770, 12, 2, 75, 100, 2, 8, 4, 105, 37, 69, 147, 712, 75, 2, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 2, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 2, 40, 319, 2, 112, 2, 11, 2, 121, 25, 70, 2, 4, 719, 2, 13, 18, 31, 62, 40, 8, 2, 4, 2, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 2, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 2, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
       "         list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 2, 270, 2, 5, 2, 2, 732, 2, 101, 405, 39, 14, 2, 4, 2, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 2, 2, 9, 24, 6, 78, 2, 17, 2, 2, 21, 27, 2, 2, 5, 2, 2, 92, 2, 4, 2, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 2, 2, 9, 6, 66, 78, 2, 4, 631, 2, 5, 2, 272, 191, 2, 6, 2, 8, 2, 2, 2, 544, 5, 383, 2, 848, 2, 2, 497, 2, 8, 2, 2, 2, 21, 60, 27, 239, 9, 43, 2, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 2, 72, 7, 51, 6, 2, 22, 4, 204, 131, 9])],\n",
       "        dtype=object),\n",
       "  array([1, 0, 0, ..., 0, 1, 0], dtype=int64)),\n",
       " (array([list([1, 591, 202, 14, 31, 6, 717, 10, 10, 2, 2, 5, 4, 360, 7, 4, 177, 2, 394, 354, 4, 123, 9, 2, 2, 2, 10, 10, 13, 92, 124, 89, 488, 2, 100, 28, 2, 14, 31, 23, 27, 2, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 2, 38, 32, 25, 2, 451, 202, 14, 6, 717]),\n",
       "         list([1, 14, 22, 2, 6, 176, 7, 2, 88, 12, 2, 23, 2, 5, 109, 943, 4, 114, 9, 55, 606, 5, 111, 7, 4, 139, 193, 273, 23, 4, 172, 270, 11, 2, 2, 4, 2, 2, 109, 2, 21, 4, 22, 2, 8, 6, 2, 2, 10, 10, 4, 105, 987, 35, 841, 2, 19, 861, 2, 5, 2, 2, 45, 55, 221, 15, 670, 2, 526, 14, 2, 4, 405, 5, 2, 7, 27, 85, 108, 131, 4, 2, 2, 2, 405, 9, 2, 133, 5, 50, 13, 104, 51, 66, 166, 14, 22, 157, 9, 4, 530, 239, 34, 2, 2, 45, 407, 31, 7, 41, 2, 105, 21, 59, 299, 12, 38, 950, 5, 2, 15, 45, 629, 488, 2, 127, 6, 52, 292, 17, 4, 2, 185, 132, 2, 2, 2, 488, 2, 47, 6, 392, 173, 4, 2, 2, 270, 2, 4, 2, 7, 4, 65, 55, 73, 11, 346, 14, 20, 9, 6, 976, 2, 7, 2, 861, 2, 5, 2, 30, 2, 2, 56, 4, 841, 5, 990, 692, 8, 4, 2, 398, 229, 10, 10, 13, 2, 670, 2, 14, 9, 31, 7, 27, 111, 108, 15, 2, 19, 2, 2, 875, 551, 14, 22, 9, 2, 21, 45, 2, 5, 45, 252, 8, 2, 6, 565, 921, 2, 39, 4, 529, 48, 25, 181, 8, 67, 35, 2, 22, 49, 238, 60, 135, 2, 14, 9, 290, 4, 58, 10, 10, 472, 45, 55, 878, 8, 169, 11, 374, 2, 25, 203, 28, 8, 818, 12, 125, 4, 2]),\n",
       "         list([1, 111, 748, 2, 2, 2, 2, 4, 87, 2, 2, 7, 31, 318, 2, 7, 4, 498, 2, 748, 63, 29, 2, 220, 686, 2, 5, 17, 12, 575, 220, 2, 17, 6, 185, 132, 2, 16, 53, 928, 11, 2, 74, 4, 438, 21, 27, 2, 589, 8, 22, 107, 2, 2, 997, 2, 8, 35, 2, 2, 11, 22, 231, 54, 29, 2, 29, 100, 2, 2, 34, 2, 2, 2, 5, 2, 98, 31, 2, 33, 6, 58, 14, 2, 2, 8, 4, 365, 7, 2, 2, 356, 346, 4, 2, 2, 63, 29, 93, 11, 2, 11, 2, 33, 6, 58, 54, 2, 431, 748, 7, 32, 2, 16, 11, 94, 2, 10, 10, 4, 993, 2, 7, 4, 2, 2, 2, 2, 8, 847, 8, 2, 121, 31, 7, 27, 86, 2, 2, 16, 6, 465, 993, 2, 2, 573, 17, 2, 42, 4, 2, 37, 473, 6, 711, 6, 2, 7, 328, 212, 70, 30, 258, 11, 220, 32, 7, 108, 21, 133, 12, 9, 55, 465, 849, 2, 53, 33, 2, 2, 37, 70, 2, 4, 2, 2, 74, 476, 37, 62, 91, 2, 169, 4, 2, 2, 146, 655, 2, 5, 258, 12, 184, 2, 546, 5, 849, 2, 7, 4, 22, 2, 18, 631, 2, 797, 7, 4, 2, 71, 348, 425, 2, 2, 19, 2, 5, 2, 11, 661, 8, 339, 2, 4, 2, 2, 7, 4, 2, 10, 10, 263, 787, 9, 270, 11, 6, 2, 4, 2, 2, 121, 4, 2, 26, 2, 19, 68, 2, 5, 28, 446, 6, 318, 2, 8, 67, 51, 36, 70, 81, 8, 2, 2, 36, 2, 8, 2, 2, 18, 6, 711, 4, 2, 26, 2, 2, 11, 14, 636, 720, 12, 426, 28, 77, 776, 8, 97, 38, 111, 2, 2, 168, 2, 2, 137, 2, 18, 27, 173, 9, 2, 17, 6, 2, 428, 2, 232, 11, 4, 2, 37, 272, 40, 2, 247, 30, 656, 6, 2, 54, 2, 2, 98, 6, 2, 40, 558, 37, 2, 98, 4, 2, 2, 15, 14, 9, 57, 2, 5, 2, 6, 275, 711, 2, 2, 2, 98, 6, 2, 10, 10, 2, 19, 14, 2, 267, 162, 711, 37, 2, 752, 98, 4, 2, 2, 90, 19, 6, 2, 7, 2, 2, 2, 4, 2, 2, 930, 8, 508, 90, 4, 2, 8, 4, 2, 17, 2, 2, 2, 4, 2, 8, 2, 189, 4, 2, 2, 2, 4, 2, 5, 95, 271, 23, 6, 2, 2, 2, 2, 33, 2, 6, 425, 2, 2, 2, 2, 7, 4, 2, 2, 469, 4, 2, 54, 4, 150, 2, 2, 280, 53, 2, 2, 18, 339, 29, 2, 27, 2, 5, 2, 68, 2, 19, 2, 2, 4, 2, 7, 263, 65, 2, 34, 6, 2, 2, 43, 159, 29, 9, 2, 9, 387, 73, 195, 584, 10, 10, 2, 4, 58, 810, 54, 14, 2, 117, 22, 16, 93, 5, 2, 4, 192, 15, 12, 16, 93, 34, 6, 2, 2, 33, 4, 2, 7, 15, 2, 2, 2, 325, 12, 62, 30, 776, 8, 67, 14, 17, 6, 2, 44, 148, 687, 2, 203, 42, 203, 24, 28, 69, 2, 2, 11, 330, 54, 29, 93, 2, 21, 845, 2, 27, 2, 7, 819, 4, 22, 2, 17, 6, 2, 787, 7, 2, 2, 2, 100, 30, 4, 2, 2, 2, 2, 42, 2, 11, 4, 2, 42, 101, 704, 7, 101, 999, 15, 2, 94, 2, 180, 5, 9, 2, 34, 2, 45, 6, 2, 22, 60, 6, 2, 31, 11, 94, 2, 96, 21, 94, 749, 9, 57, 975]),\n",
       "         ...,\n",
       "         list([1, 13, 2, 15, 8, 135, 14, 9, 35, 32, 46, 394, 20, 62, 30, 2, 21, 45, 184, 78, 4, 2, 910, 769, 2, 2, 395, 2, 5, 2, 11, 119, 2, 89, 2, 4, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 7, 185, 2, 284, 2, 2, 37, 315, 4, 226, 20, 272, 2, 40, 29, 152, 60, 181, 8, 30, 50, 553, 362, 80, 119, 12, 21, 846, 2]),\n",
       "         list([1, 11, 119, 241, 9, 4, 840, 20, 12, 468, 15, 94, 2, 562, 791, 39, 4, 86, 107, 8, 97, 14, 31, 33, 4, 2, 7, 743, 46, 2, 9, 2, 5, 4, 768, 47, 8, 79, 90, 145, 164, 162, 50, 6, 501, 119, 7, 9, 4, 78, 232, 15, 16, 224, 11, 4, 333, 20, 4, 985, 200, 5, 2, 5, 9, 2, 8, 79, 357, 4, 20, 47, 220, 57, 206, 139, 11, 12, 5, 55, 117, 212, 13, 2, 92, 124, 51, 45, 2, 71, 536, 13, 520, 14, 20, 6, 2, 7, 470]),\n",
       "         list([1, 6, 52, 2, 430, 22, 9, 220, 2, 8, 28, 2, 519, 2, 6, 769, 15, 47, 6, 2, 2, 8, 114, 5, 33, 222, 31, 55, 184, 704, 2, 2, 19, 346, 2, 5, 6, 364, 350, 4, 184, 2, 9, 133, 2, 11, 2, 2, 21, 4, 2, 2, 570, 50, 2, 2, 9, 6, 2, 17, 6, 2, 2, 21, 17, 6, 2, 232, 2, 2, 29, 266, 56, 96, 346, 194, 308, 9, 194, 21, 29, 218, 2, 19, 4, 78, 173, 7, 27, 2, 2, 2, 718, 2, 9, 6, 2, 17, 210, 5, 2, 2, 47, 77, 395, 14, 172, 173, 18, 2, 2, 2, 82, 127, 27, 173, 11, 6, 392, 217, 21, 50, 9, 57, 65, 12, 2, 53, 40, 35, 390, 7, 11, 4, 2, 7, 4, 314, 74, 6, 792, 22, 2, 19, 714, 727, 2, 382, 4, 91, 2, 439, 19, 14, 20, 9, 2, 2, 2, 4, 756, 25, 124, 4, 31, 12, 16, 93, 804, 34, 2, 2])],\n",
       "        dtype=object),\n",
       "  array([0, 1, 1, ..., 0, 0, 0], dtype=int64)))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Limit the vocabulary to the top 500 words using num_words\n",
    "imdb.load_data(num_words=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([list([2, 14, 22, 16, 43, 530, 973, 2, 2, 65, 458, 2, 66, 2, 2, 173, 36, 256, 2, 25, 100, 43, 838, 112, 50, 670, 2, 2, 35, 480, 284, 2, 150, 2, 172, 112, 167, 2, 336, 385, 39, 2, 172, 2, 2, 17, 546, 38, 13, 447, 2, 192, 50, 16, 2, 147, 2, 19, 14, 22, 2, 2, 2, 469, 2, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 2, 2, 22, 17, 515, 17, 12, 16, 626, 18, 2, 2, 62, 386, 12, 2, 316, 2, 106, 2, 2, 2, 2, 16, 480, 66, 2, 33, 2, 130, 12, 16, 38, 619, 2, 25, 124, 51, 36, 135, 48, 25, 2, 33, 2, 22, 12, 215, 28, 77, 52, 2, 14, 407, 16, 82, 2, 2, 2, 107, 117, 2, 15, 256, 2, 2, 2, 2, 2, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 2, 2, 2, 2, 13, 104, 88, 2, 381, 15, 297, 98, 32, 2, 56, 26, 141, 2, 194, 2, 18, 2, 226, 22, 21, 134, 476, 26, 480, 2, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 2, 226, 65, 16, 38, 2, 88, 12, 16, 283, 2, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]),\n",
       "         list([2, 194, 2, 194, 2, 78, 228, 2, 2, 2, 2, 2, 134, 26, 2, 715, 2, 118, 2, 14, 394, 20, 13, 119, 954, 189, 102, 2, 207, 110, 2, 21, 14, 69, 188, 2, 30, 23, 2, 2, 249, 126, 93, 2, 114, 2, 2, 2, 2, 647, 2, 116, 2, 35, 2, 2, 229, 2, 340, 2, 2, 118, 2, 2, 130, 2, 19, 2, 2, 2, 89, 29, 952, 46, 37, 2, 455, 2, 45, 43, 38, 2, 2, 398, 2, 2, 26, 2, 2, 163, 11, 2, 2, 2, 2, 2, 194, 775, 2, 2, 2, 349, 2, 148, 605, 2, 2, 15, 123, 125, 68, 2, 2, 15, 349, 165, 2, 98, 2, 2, 228, 2, 43, 2, 2, 15, 299, 120, 2, 120, 174, 11, 220, 175, 136, 50, 2, 2, 228, 2, 2, 2, 656, 245, 2, 2, 2, 2, 131, 152, 491, 18, 2, 32, 2, 2, 14, 2, 2, 371, 78, 22, 625, 64, 2, 2, 2, 168, 145, 23, 2, 2, 15, 16, 2, 2, 2, 28, 2, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
       "         list([2, 14, 47, 2, 30, 31, 2, 2, 249, 108, 2, 2, 2, 54, 61, 369, 13, 71, 149, 14, 22, 112, 2, 2, 311, 12, 16, 2, 33, 75, 43, 2, 296, 2, 86, 320, 35, 534, 19, 263, 2, 2, 2, 2, 33, 89, 78, 12, 66, 16, 2, 360, 2, 2, 58, 316, 334, 11, 2, 2, 43, 645, 662, 2, 257, 85, 2, 42, 2, 2, 83, 68, 2, 15, 36, 165, 2, 278, 36, 69, 2, 780, 2, 106, 14, 2, 2, 18, 2, 22, 12, 215, 28, 610, 40, 2, 87, 326, 23, 2, 21, 23, 22, 12, 272, 40, 57, 31, 11, 2, 22, 47, 2, 2, 51, 2, 170, 23, 595, 116, 595, 2, 13, 191, 79, 638, 89, 2, 14, 2, 2, 106, 607, 624, 35, 534, 2, 227, 2, 129, 113]),\n",
       "         ...,\n",
       "         list([2, 11, 2, 230, 245, 2, 2, 2, 2, 446, 2, 45, 2, 84, 2, 2, 21, 2, 912, 84, 2, 325, 725, 134, 2, 2, 84, 2, 36, 28, 57, 2, 21, 2, 140, 2, 703, 2, 2, 84, 56, 18, 2, 14, 2, 31, 2, 2, 2, 2, 2, 2, 2, 18, 2, 20, 207, 110, 563, 12, 2, 2, 2, 2, 97, 2, 20, 53, 2, 74, 2, 460, 364, 2, 29, 270, 11, 960, 108, 45, 40, 29, 2, 395, 11, 2, 2, 500, 2, 2, 89, 364, 70, 29, 140, 2, 64, 2, 11, 2, 2, 26, 178, 2, 529, 443, 2, 2, 27, 710, 117, 2, 2, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 2, 2, 10, 10, 288, 2, 2, 34, 2, 2, 2, 65, 496, 2, 231, 2, 790, 2, 2, 320, 234, 2, 234, 2, 2, 2, 496, 2, 139, 929, 2, 2, 2, 2, 2, 18, 2, 2, 2, 250, 11, 2, 2, 2, 2, 2, 747, 2, 372, 2, 2, 541, 2, 2, 2, 59, 2, 2, 2, 2]),\n",
       "         list([2, 2, 2, 69, 72, 2, 13, 610, 930, 2, 12, 582, 23, 2, 16, 484, 685, 54, 349, 11, 2, 2, 45, 58, 2, 13, 197, 12, 16, 43, 23, 2, 2, 62, 30, 145, 402, 11, 2, 51, 575, 32, 61, 369, 71, 66, 770, 12, 2, 75, 100, 2, 2, 2, 105, 37, 69, 147, 712, 75, 2, 44, 257, 390, 2, 69, 263, 514, 105, 50, 286, 2, 23, 2, 123, 13, 161, 40, 2, 421, 2, 116, 16, 897, 13, 2, 40, 319, 2, 112, 2, 11, 2, 121, 25, 70, 2, 2, 719, 2, 13, 18, 31, 62, 40, 2, 2, 2, 2, 2, 14, 123, 2, 942, 25, 2, 721, 12, 145, 2, 202, 12, 160, 580, 202, 12, 2, 52, 58, 2, 92, 401, 728, 12, 39, 14, 251, 2, 15, 251, 2, 2, 12, 38, 84, 80, 124, 12, 2, 23]),\n",
       "         list([2, 17, 2, 194, 337, 2, 2, 204, 22, 45, 254, 2, 106, 14, 123, 2, 2, 270, 2, 2, 2, 2, 732, 2, 101, 405, 39, 14, 2, 2, 2, 2, 115, 50, 305, 12, 47, 2, 168, 2, 235, 2, 38, 111, 699, 102, 2, 2, 2, 2, 2, 24, 2, 78, 2, 17, 2, 2, 21, 27, 2, 2, 2, 2, 2, 92, 2, 2, 2, 2, 2, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 2, 97, 12, 157, 21, 2, 2, 2, 2, 66, 78, 2, 2, 631, 2, 2, 2, 272, 191, 2, 2, 2, 2, 2, 2, 2, 544, 2, 383, 2, 848, 2, 2, 497, 2, 2, 2, 2, 2, 21, 60, 27, 239, 2, 43, 2, 209, 405, 10, 10, 12, 764, 40, 2, 248, 20, 12, 16, 2, 174, 2, 72, 2, 51, 2, 2, 22, 2, 204, 131, 2])],\n",
       "        dtype=object),\n",
       "  array([1, 0, 0, ..., 0, 1, 0], dtype=int64)),\n",
       " (array([list([2, 591, 202, 14, 31, 2, 717, 10, 10, 2, 2, 2, 2, 360, 2, 2, 177, 2, 394, 354, 2, 123, 2, 2, 2, 2, 10, 10, 13, 92, 124, 89, 488, 2, 100, 28, 2, 14, 31, 23, 27, 2, 29, 220, 468, 2, 124, 14, 286, 170, 2, 157, 46, 2, 27, 239, 16, 179, 2, 38, 32, 25, 2, 451, 202, 14, 2, 717]),\n",
       "         list([2, 14, 22, 2, 2, 176, 2, 2, 88, 12, 2, 23, 2, 2, 109, 943, 2, 114, 2, 55, 606, 2, 111, 2, 2, 139, 193, 273, 23, 2, 172, 270, 11, 2, 2, 2, 2, 2, 109, 2, 21, 2, 22, 2, 2, 2, 2, 2, 10, 10, 2, 105, 987, 35, 841, 2, 19, 861, 2, 2, 2, 2, 45, 55, 221, 15, 670, 2, 526, 14, 2, 2, 405, 2, 2, 2, 27, 85, 108, 131, 2, 2, 2, 2, 405, 2, 2, 133, 2, 50, 13, 104, 51, 66, 166, 14, 22, 157, 2, 2, 530, 239, 34, 2, 2, 45, 407, 31, 2, 41, 2, 105, 21, 59, 299, 12, 38, 950, 2, 2, 15, 45, 629, 488, 2, 127, 2, 52, 292, 17, 2, 2, 185, 132, 2, 2, 2, 488, 2, 47, 2, 392, 173, 2, 2, 2, 270, 2, 2, 2, 2, 2, 65, 55, 73, 11, 346, 14, 20, 2, 2, 976, 2, 2, 2, 861, 2, 2, 2, 30, 2, 2, 56, 2, 841, 2, 990, 692, 2, 2, 2, 398, 229, 10, 10, 13, 2, 670, 2, 14, 2, 31, 2, 27, 111, 108, 15, 2, 19, 2, 2, 875, 551, 14, 22, 2, 2, 21, 45, 2, 2, 45, 252, 2, 2, 2, 565, 921, 2, 39, 2, 529, 48, 25, 181, 2, 67, 35, 2, 22, 49, 238, 60, 135, 2, 14, 2, 290, 2, 58, 10, 10, 472, 45, 55, 878, 2, 169, 11, 374, 2, 25, 203, 28, 2, 818, 12, 125, 2, 2]),\n",
       "         list([2, 111, 748, 2, 2, 2, 2, 2, 87, 2, 2, 2, 31, 318, 2, 2, 2, 498, 2, 748, 63, 29, 2, 220, 686, 2, 2, 17, 12, 575, 220, 2, 17, 2, 185, 132, 2, 16, 53, 928, 11, 2, 74, 2, 438, 21, 27, 2, 589, 2, 22, 107, 2, 2, 997, 2, 2, 35, 2, 2, 11, 22, 231, 54, 29, 2, 29, 100, 2, 2, 34, 2, 2, 2, 2, 2, 98, 31, 2, 33, 2, 58, 14, 2, 2, 2, 2, 365, 2, 2, 2, 356, 346, 2, 2, 2, 63, 29, 93, 11, 2, 11, 2, 33, 2, 58, 54, 2, 431, 748, 2, 32, 2, 16, 11, 94, 2, 10, 10, 2, 993, 2, 2, 2, 2, 2, 2, 2, 2, 847, 2, 2, 121, 31, 2, 27, 86, 2, 2, 16, 2, 465, 993, 2, 2, 573, 17, 2, 42, 2, 2, 37, 473, 2, 711, 2, 2, 2, 328, 212, 70, 30, 258, 11, 220, 32, 2, 108, 21, 133, 12, 2, 55, 465, 849, 2, 53, 33, 2, 2, 37, 70, 2, 2, 2, 2, 74, 476, 37, 62, 91, 2, 169, 2, 2, 2, 146, 655, 2, 2, 258, 12, 184, 2, 546, 2, 849, 2, 2, 2, 22, 2, 18, 631, 2, 797, 2, 2, 2, 71, 348, 425, 2, 2, 19, 2, 2, 2, 11, 661, 2, 339, 2, 2, 2, 2, 2, 2, 2, 10, 10, 263, 787, 2, 270, 11, 2, 2, 2, 2, 2, 121, 2, 2, 26, 2, 19, 68, 2, 2, 28, 446, 2, 318, 2, 2, 67, 51, 36, 70, 81, 2, 2, 2, 36, 2, 2, 2, 2, 18, 2, 711, 2, 2, 26, 2, 2, 11, 14, 636, 720, 12, 426, 28, 77, 776, 2, 97, 38, 111, 2, 2, 168, 2, 2, 137, 2, 18, 27, 173, 2, 2, 17, 2, 2, 428, 2, 232, 11, 2, 2, 37, 272, 40, 2, 247, 30, 656, 2, 2, 54, 2, 2, 98, 2, 2, 40, 558, 37, 2, 98, 2, 2, 2, 15, 14, 2, 57, 2, 2, 2, 2, 275, 711, 2, 2, 2, 98, 2, 2, 10, 10, 2, 19, 14, 2, 267, 162, 711, 37, 2, 752, 98, 2, 2, 2, 90, 19, 2, 2, 2, 2, 2, 2, 2, 2, 2, 930, 2, 508, 90, 2, 2, 2, 2, 2, 17, 2, 2, 2, 2, 2, 2, 2, 189, 2, 2, 2, 2, 2, 2, 2, 95, 271, 23, 2, 2, 2, 2, 2, 33, 2, 2, 425, 2, 2, 2, 2, 2, 2, 2, 2, 469, 2, 2, 54, 2, 150, 2, 2, 280, 53, 2, 2, 18, 339, 29, 2, 27, 2, 2, 2, 68, 2, 19, 2, 2, 2, 2, 2, 263, 65, 2, 34, 2, 2, 2, 43, 159, 29, 2, 2, 2, 387, 73, 195, 584, 10, 10, 2, 2, 58, 810, 54, 14, 2, 117, 22, 16, 93, 2, 2, 2, 192, 15, 12, 16, 93, 34, 2, 2, 2, 33, 2, 2, 2, 15, 2, 2, 2, 325, 12, 62, 30, 776, 2, 67, 14, 17, 2, 2, 44, 148, 687, 2, 203, 42, 203, 24, 28, 69, 2, 2, 11, 330, 54, 29, 93, 2, 21, 845, 2, 27, 2, 2, 819, 2, 22, 2, 17, 2, 2, 787, 2, 2, 2, 2, 100, 30, 2, 2, 2, 2, 2, 42, 2, 11, 2, 2, 42, 101, 704, 2, 101, 999, 15, 2, 94, 2, 180, 2, 2, 2, 34, 2, 45, 2, 2, 22, 60, 2, 2, 31, 11, 94, 2, 96, 21, 94, 749, 2, 57, 975]),\n",
       "         ...,\n",
       "         list([2, 13, 2, 15, 2, 135, 14, 2, 35, 32, 46, 394, 20, 62, 30, 2, 21, 45, 184, 78, 2, 2, 910, 769, 2, 2, 395, 2, 2, 2, 11, 119, 2, 89, 2, 2, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 2, 185, 2, 284, 2, 2, 37, 315, 2, 226, 20, 272, 2, 40, 29, 152, 60, 181, 2, 30, 50, 553, 362, 80, 119, 12, 21, 846, 2]),\n",
       "         list([2, 11, 119, 241, 2, 2, 840, 20, 12, 468, 15, 94, 2, 562, 791, 39, 2, 86, 107, 2, 97, 14, 31, 33, 2, 2, 2, 743, 46, 2, 2, 2, 2, 2, 768, 47, 2, 79, 90, 145, 164, 162, 50, 2, 501, 119, 2, 2, 2, 78, 232, 15, 16, 224, 11, 2, 333, 20, 2, 985, 200, 2, 2, 2, 2, 2, 2, 79, 357, 2, 20, 47, 220, 57, 206, 139, 11, 12, 2, 55, 117, 212, 13, 2, 92, 124, 51, 45, 2, 71, 536, 13, 520, 14, 20, 2, 2, 2, 470]),\n",
       "         list([2, 2, 52, 2, 430, 22, 2, 220, 2, 2, 28, 2, 519, 2, 2, 769, 15, 47, 2, 2, 2, 2, 114, 2, 33, 222, 31, 55, 184, 704, 2, 2, 19, 346, 2, 2, 2, 364, 350, 2, 184, 2, 2, 133, 2, 11, 2, 2, 21, 2, 2, 2, 570, 50, 2, 2, 2, 2, 2, 17, 2, 2, 2, 21, 17, 2, 2, 232, 2, 2, 29, 266, 56, 96, 346, 194, 308, 2, 194, 21, 29, 218, 2, 19, 2, 78, 173, 2, 27, 2, 2, 2, 718, 2, 2, 2, 2, 17, 210, 2, 2, 2, 47, 77, 395, 14, 172, 173, 18, 2, 2, 2, 82, 127, 27, 173, 11, 2, 392, 217, 21, 50, 2, 57, 65, 12, 2, 53, 40, 35, 390, 2, 11, 2, 2, 2, 2, 314, 74, 2, 792, 22, 2, 19, 714, 727, 2, 382, 2, 91, 2, 439, 19, 14, 20, 2, 2, 2, 2, 2, 756, 25, 124, 2, 31, 12, 16, 93, 804, 34, 2, 2])],\n",
       "        dtype=object),\n",
       "  array([0, 1, 1, ..., 0, 0, 0], dtype=int64)))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ignore the top 10 most frequent words using skip_top\n",
    "imdb.load_data(skip_top=10, num_words=1000, oov_char=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
       "         list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 36893, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 25249, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 46151, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
       "         list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 44076, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 51428, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
       "         ...,\n",
       "         list([1, 518, 21, 55, 1713, 6, 20, 716, 6, 65, 38, 73, 15, 12, 220, 461, 878, 14, 20, 716, 450, 537, 38, 73, 5189, 15, 12, 16, 4, 86, 171, 211, 6, 20, 13, 100, 24, 106, 8, 20252, 12, 16, 99, 147, 5, 4, 105, 38, 565, 15, 149, 12, 877, 6, 965, 1651, 319, 134, 289, 349, 5, 68, 2166, 855, 19, 68, 10082, 31, 11, 843, 400, 569, 72, 99, 254, 150, 13, 28, 296, 11, 94, 6274, 209, 21501, 450, 211, 5, 13, 923, 51, 13, 210, 6677, 14, 20, 9, 6, 991, 4, 487, 4, 116, 4, 10409, 7, 450, 537, 209, 112, 60, 4, 222, 227, 5303, 285, 44, 14, 20, 9, 3160, 1542, 1809, 2128, 57, 594, 12, 434, 215, 28, 1816, 98]),\n",
       "         list([1, 14, 22, 714, 8012, 4, 921, 2124, 4, 905, 1488, 5, 4, 350, 2501, 354, 7, 1691, 1612, 349, 13, 1610, 12, 23, 6, 13574, 5, 16, 2664, 15, 13, 69, 24, 557, 7, 12, 159, 10, 10, 13, 81, 24, 124, 48, 14, 16, 14513, 3667, 2016, 21, 4, 1794, 4, 8466, 5, 943, 7, 4, 105, 17, 73, 17, 4, 49, 1096, 370, 157, 3392, 4, 109, 33241, 299, 32, 1467, 6, 1249, 744, 10, 10, 4, 8466, 200, 1593, 5, 14513, 1367, 4, 172, 389, 1175, 75, 219, 11, 1513, 890, 19, 1593, 5, 1441, 6909, 6239, 9, 389, 11, 41, 105, 1302, 4182, 5, 13291, 6, 8022, 23, 41, 105, 11, 33, 297, 11, 4, 5322, 7, 4, 1635, 59, 9, 2227, 5, 246, 31, 70, 9530, 19, 41, 33, 4, 172, 58, 10, 10, 50, 26, 49, 388, 121, 13, 235, 4, 114, 9281, 6, 1229, 5, 4, 388, 200, 33241, 5, 27, 1233, 980, 220, 306, 398, 18, 160, 22, 33241, 266, 125, 17, 160, 109, 32, 295, 21, 148, 26, 1403, 5266, 10, 10, 14, 22, 215, 30, 448, 23, 6, 283, 65, 42, 215, 28, 77, 398, 34, 294, 37, 1452, 134, 2490, 13, 967, 12, 709, 46, 7, 6, 878, 158, 10, 10]),\n",
       "         list([1, 13, 219, 14, 20, 23, 248, 5, 447, 12, 13, 244, 6, 147, 1690, 22, 337, 5, 14, 31, 16, 87, 4, 177, 16, 93, 7, 49, 66, 221, 84, 8246, 9, 210, 87, 5, 1024, 31711, 9, 11, 6, 2756, 7, 27, 205, 29, 70, 297, 199, 212, 5, 708, 11, 4, 172, 20, 40, 171, 409, 70, 4, 65, 347, 9, 87, 99, 4, 197, 7, 112, 502, 8, 794, 6, 58, 347, 7, 51, 80, 593, 5, 8, 361, 14, 58, 347, 8, 3621, 6, 4564, 1690, 9, 35, 221, 326, 5, 14, 20, 961, 12, 46, 11, 141, 6, 96, 15, 9, 220, 484, 867])],\n",
       "        dtype=object),\n",
       "  array([1, 0, 0, ..., 1, 1, 1], dtype=int64)),\n",
       " (array([list([1, 14, 9, 31, 7, 4, 249, 108, 13, 28, 110, 11, 6, 137, 10, 10, 4, 439, 9, 15, 12, 152, 124, 726, 12, 494, 8, 30, 35, 1089, 993, 22, 43675, 42, 35, 3435, 9, 10528, 17, 6, 959, 12, 996, 23, 32, 6566, 10, 10, 4, 116, 9, 2526, 4, 2559, 125, 1489, 5, 4, 424, 3881, 1149, 10, 10, 14746, 8035, 9, 242, 4, 118, 155, 44, 14, 22, 21, 15, 218, 6, 52, 155, 252, 29, 47, 35, 1596, 5, 61226, 168, 21, 1116, 29, 191, 165, 511, 43, 168, 33, 89, 29, 12482, 54, 27, 4727, 889, 10, 10, 66, 92, 106, 14, 22, 49, 135, 12, 738, 3260, 4719, 13, 135, 31, 9, 99, 111]),\n",
       "         list([1, 4, 7591, 248, 7, 108, 5077, 28, 13, 421, 38, 117, 11728, 8, 105, 5077, 28, 13, 77, 93, 8, 4032, 34, 141, 3648, 414, 15670, 1316, 3264, 7678, 28837, 2161, 8464, 2986, 732, 12435, 61019, 46432, 798, 14, 22, 17, 48, 12, 71, 129, 24558]),\n",
       "         list([1, 160, 12576, 212, 270, 11, 4, 1547, 12, 186, 15, 4, 612, 31, 1622, 1466, 18, 1205, 16, 11, 14, 172, 719, 1547, 17, 38, 111, 7, 12563, 5, 71375, 108, 26, 270, 50, 5, 137, 14, 9, 246, 160, 31, 12, 9, 275, 195, 5, 73, 93, 15, 13, 131, 510, 12, 10, 10, 16866, 9, 928, 11, 6, 1155, 74, 644, 267, 5, 116, 7376, 30258, 13, 104, 442, 424, 8, 30, 6, 117, 1155, 151, 11, 41, 3992, 523, 59, 9, 99, 185, 8, 30, 928, 11, 349, 73, 16866, 127, 24, 1497, 41, 1417, 5, 515, 29, 5, 7376, 521, 245, 18, 49, 1356, 253, 183, 79, 2732, 54, 4, 3992, 106, 9, 2586, 16866, 659, 12, 5, 408, 12, 8, 7376, 17, 6, 3470, 5, 111, 712, 959, 10, 10, 542, 1794, 5, 4, 192, 15, 14, 20, 122, 24, 5390, 99, 76, 23, 706, 2764, 21, 6, 3793, 114, 97, 14, 6, 1036, 5, 737, 117, 22]),\n",
       "         ...,\n",
       "         list([1, 13, 1408, 15, 8, 135, 14, 9, 35, 32, 46, 394, 20, 62, 30, 5093, 21, 45, 184, 78, 4, 1492, 910, 769, 2290, 2515, 395, 4257, 5, 1454, 11, 119, 16946, 89, 1036, 4, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 7, 185, 2280, 284, 1842, 60664, 37, 315, 4, 226, 20, 272, 2942, 40, 29, 152, 60, 181, 8, 30, 50, 553, 362, 80, 119, 12, 21, 846, 5518]),\n",
       "         list([1, 11, 119, 241, 9, 4, 840, 20, 12, 468, 15, 94, 3684, 562, 791, 39, 4, 86, 107, 8, 97, 14, 31, 33, 4, 2960, 7, 743, 46, 1028, 9, 3531, 5, 4, 768, 47, 8, 79, 90, 145, 164, 162, 50, 6, 501, 119, 7, 9, 4, 78, 232, 15, 16, 224, 11, 4, 333, 20, 4, 985, 200, 5, 28739, 5, 9, 1861, 8, 79, 357, 4, 20, 47, 220, 57, 206, 139, 11, 12, 5, 55, 117, 212, 13, 1276, 92, 124, 51, 45, 1188, 71, 536, 13, 520, 14, 20, 6, 2302, 7, 470]),\n",
       "         list([1, 6, 52, 7465, 430, 22, 9, 220, 2594, 8, 28, 24357, 519, 3227, 6, 769, 15, 47, 6, 3482, 4067, 8, 114, 5, 33, 222, 31, 55, 184, 704, 5586, 18020, 19, 346, 3153, 5, 6, 364, 350, 4, 184, 5586, 9, 133, 1810, 11, 5417, 13226, 21, 4, 7298, 42657, 570, 50, 2005, 2643, 9, 6, 1249, 17, 6, 25194, 27803, 21, 17, 6, 1211, 232, 1138, 2249, 29, 266, 56, 96, 346, 194, 308, 9, 194, 21, 29, 218, 1078, 19, 4, 78, 173, 7, 27, 20067, 5698, 3406, 718, 21264, 9, 6, 6907, 17, 210, 5, 3281, 5677, 47, 77, 395, 14, 172, 173, 18, 2740, 2931, 4517, 82, 127, 27, 173, 11, 6, 392, 217, 21, 50, 9, 57, 65, 12, 14274, 53, 40, 35, 390, 7, 11, 4, 3567, 7, 4, 314, 74, 6, 792, 22, 16261, 19, 714, 727, 5205, 382, 4, 91, 6533, 439, 19, 14, 20, 9, 1441, 5805, 1118, 4, 756, 25, 124, 4, 31, 12, 16, 93, 804, 34, 2005, 2643])],\n",
       "        dtype=object),\n",
       "  array([0, 0, 1, ..., 0, 0, 0], dtype=int64)))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Limit the sequence lengths to 500 using maxlen\n",
    "\n",
    "imdb.load_data(maxlen=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
       "         list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 36893, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 25249, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 46151, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
       "         list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 44076, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 51428, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
       "         ...,\n",
       "         list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 86527, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 14532, 325, 725, 134, 15271, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 11656, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 26094, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 17793, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 14492, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 17793, 5, 27, 710, 117, 74936, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 17793, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 17793, 7750, 5, 4241, 18, 4, 8497, 13164, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 11027, 4, 3586, 22459]),\n",
       "         list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 21469, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 40691, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 29455, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 11418, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 21213, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
       "         list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 12815, 270, 14437, 5, 16923, 12255, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 16553, 21, 27, 9685, 6139, 5, 29043, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 85010, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 70907, 10755, 544, 5, 383, 1271, 848, 1468, 12183, 497, 16876, 8, 1597, 8778, 19280, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
       "        dtype=object),\n",
       "  array([1, 0, 0, ..., 0, 1, 0], dtype=int64)),\n",
       " (array([list([1, 591, 202, 14, 31, 6, 717, 10, 10, 18142, 10698, 5, 4, 360, 7, 4, 177, 5760, 394, 354, 4, 123, 9, 1035, 1035, 1035, 10, 10, 13, 92, 124, 89, 488, 7944, 100, 28, 1668, 14, 31, 23, 27, 7479, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 15387, 38, 32, 25, 7944, 451, 202, 14, 6, 717]),\n",
       "         list([1, 14, 22, 3443, 6, 176, 7, 5063, 88, 12, 2679, 23, 1310, 5, 109, 943, 4, 114, 9, 55, 606, 5, 111, 7, 4, 139, 193, 273, 23, 4, 172, 270, 11, 7216, 10626, 4, 8463, 2801, 109, 1603, 21, 4, 22, 3861, 8, 6, 1193, 1330, 10, 10, 4, 105, 987, 35, 841, 16873, 19, 861, 1074, 5, 1987, 17975, 45, 55, 221, 15, 670, 5304, 526, 14, 1069, 4, 405, 5, 2438, 7, 27, 85, 108, 131, 4, 5045, 5304, 3884, 405, 9, 3523, 133, 5, 50, 13, 104, 51, 66, 166, 14, 22, 157, 9, 4, 530, 239, 34, 8463, 2801, 45, 407, 31, 7, 41, 3778, 105, 21, 59, 299, 12, 38, 950, 5, 4521, 15, 45, 629, 488, 2733, 127, 6, 52, 292, 17, 4, 6936, 185, 132, 1988, 5304, 1799, 488, 2693, 47, 6, 392, 173, 4, 21686, 4378, 270, 2352, 4, 1500, 7, 4, 65, 55, 73, 11, 346, 14, 20, 9, 6, 976, 2078, 7, 5293, 861, 12746, 5, 4182, 30, 3127, 23651, 56, 4, 841, 5, 990, 692, 8, 4, 1669, 398, 229, 10, 10, 13, 2822, 670, 5304, 14, 9, 31, 7, 27, 111, 108, 15, 2033, 19, 7836, 1429, 875, 551, 14, 22, 9, 1193, 21, 45, 4829, 5, 45, 252, 8, 12508, 6, 565, 921, 3639, 39, 4, 529, 48, 25, 181, 8, 67, 35, 1732, 22, 49, 238, 60, 135, 1162, 14, 9, 290, 4, 58, 10, 10, 472, 45, 55, 878, 8, 169, 11, 374, 5687, 25, 203, 28, 8, 818, 12, 125, 4, 3077]),\n",
       "         list([1, 111, 748, 4368, 1133, 33782, 24563, 4, 87, 1551, 1262, 7, 31, 318, 9459, 7, 4, 498, 5076, 748, 63, 29, 5161, 220, 686, 10941, 5, 17, 12, 575, 220, 2507, 17, 6, 185, 132, 24563, 16, 53, 928, 11, 51278, 74, 4, 438, 21, 27, 10044, 589, 8, 22, 107, 20123, 19550, 997, 1638, 8, 35, 2076, 9019, 11, 22, 231, 54, 29, 1706, 29, 100, 18995, 2425, 34, 12998, 8738, 48078, 5, 19353, 98, 31, 2122, 33, 6, 58, 14, 3808, 1638, 8, 4, 365, 7, 2789, 3761, 356, 346, 4, 27608, 1060, 63, 29, 93, 11, 5421, 11, 15236, 33, 6, 58, 54, 1270, 431, 748, 7, 32, 2580, 16, 11, 94, 19469, 10, 10, 4, 993, 45222, 7, 4, 1766, 2634, 2164, 24563, 8, 847, 8, 1450, 121, 31, 7, 27, 86, 2663, 10760, 16, 6, 465, 993, 2006, 30995, 573, 17, 61862, 42, 4, 17345, 37, 473, 6, 711, 6, 8869, 7, 328, 212, 70, 30, 258, 11, 220, 32, 7, 108, 21, 133, 12, 9, 55, 465, 849, 3711, 53, 33, 2071, 1969, 37, 70, 1144, 4, 5940, 1409, 74, 476, 37, 62, 91, 1329, 169, 4, 1330, 10104, 146, 655, 2212, 5, 258, 12, 184, 10104, 546, 5, 849, 10333, 7, 4, 22, 1436, 18, 631, 1386, 797, 7, 4, 8712, 71, 348, 425, 4320, 1061, 19, 10288, 5, 12141, 11, 661, 8, 339, 17863, 4, 2455, 11434, 7, 4, 1962, 10, 10, 263, 787, 9, 270, 11, 6, 9466, 4, 61862, 48414, 121, 4, 5437, 26, 4434, 19, 68, 1372, 5, 28, 446, 6, 318, 7149, 8, 67, 51, 36, 70, 81, 8, 4392, 2294, 36, 1197, 8, 68411, 25399, 18, 6, 711, 4, 9909, 26, 10296, 1125, 11, 14, 636, 720, 12, 426, 28, 77, 776, 8, 97, 38, 111, 7489, 6175, 168, 1239, 5189, 137, 25399, 18, 27, 173, 9, 2399, 17, 6, 12397, 428, 14657, 232, 11, 4, 8014, 37, 272, 40, 2708, 247, 30, 656, 6, 13182, 54, 25399, 3292, 98, 6, 2840, 40, 558, 37, 6093, 98, 4, 17345, 1197, 15, 14, 9, 57, 4893, 5, 4659, 6, 275, 711, 7937, 25399, 3292, 98, 6, 31036, 10, 10, 6639, 19, 14, 10241, 267, 162, 711, 37, 5900, 752, 98, 4, 17345, 2378, 90, 19, 6, 73284, 7, 36744, 1810, 77553, 4, 4770, 3183, 930, 8, 508, 90, 4, 1317, 8, 4, 48414, 17, 15454, 3965, 1853, 4, 1494, 8, 4468, 189, 4, 31036, 6287, 5774, 4, 4770, 5, 95, 271, 23, 6, 7742, 6063, 21627, 5437, 33, 1526, 6, 425, 3155, 33697, 4535, 1636, 7, 4, 4669, 11966, 469, 4, 4552, 54, 4, 150, 5664, 17345, 280, 53, 68411, 25399, 18, 339, 29, 1978, 27, 7885, 5, 17303, 68, 1830, 19, 6571, 14605, 4, 1515, 7, 263, 65, 2132, 34, 6, 5680, 7489, 43, 159, 29, 9, 4706, 9, 387, 73, 195, 584, 10, 10, 1069, 4, 58, 810, 54, 14, 6078, 117, 22, 16, 93, 5, 1069, 4, 192, 15, 12, 16, 93, 34, 6, 1766, 28228, 33, 4, 5673, 7, 15, 18760, 9252, 3286, 325, 12, 62, 30, 776, 8, 67, 14, 17, 6, 12214, 44, 148, 687, 24563, 203, 42, 203, 24, 28, 69, 32157, 6676, 11, 330, 54, 29, 93, 61862, 21, 845, 14148, 27, 1099, 7, 819, 4, 22, 1407, 17, 6, 14967, 787, 7, 2460, 19569, 61862, 100, 30, 4, 3737, 3617, 3169, 2321, 42, 1898, 11, 4, 3814, 42, 101, 704, 7, 101, 999, 15, 1625, 94, 2926, 180, 5, 9, 9101, 34, 15205, 45, 6, 1429, 22, 60, 6, 1220, 31, 11, 94, 6408, 96, 21, 94, 749, 9, 57, 975]),\n",
       "         ...,\n",
       "         list([1, 13, 1408, 15, 8, 135, 14, 9, 35, 32, 46, 394, 20, 62, 30, 5093, 21, 45, 184, 78, 4, 1492, 910, 769, 2290, 2515, 395, 4257, 5, 1454, 11, 119, 16946, 89, 1036, 4, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 7, 185, 2280, 284, 1842, 60664, 37, 315, 4, 226, 20, 272, 2942, 40, 29, 152, 60, 181, 8, 30, 50, 553, 362, 80, 119, 12, 21, 846, 5518]),\n",
       "         list([1, 11, 119, 241, 9, 4, 840, 20, 12, 468, 15, 94, 3684, 562, 791, 39, 4, 86, 107, 8, 97, 14, 31, 33, 4, 2960, 7, 743, 46, 1028, 9, 3531, 5, 4, 768, 47, 8, 79, 90, 145, 164, 162, 50, 6, 501, 119, 7, 9, 4, 78, 232, 15, 16, 224, 11, 4, 333, 20, 4, 985, 200, 5, 28739, 5, 9, 1861, 8, 79, 357, 4, 20, 47, 220, 57, 206, 139, 11, 12, 5, 55, 117, 212, 13, 1276, 92, 124, 51, 45, 1188, 71, 536, 13, 520, 14, 20, 6, 2302, 7, 470]),\n",
       "         list([1, 6, 52, 7465, 430, 22, 9, 220, 2594, 8, 28, 24357, 519, 3227, 6, 769, 15, 47, 6, 3482, 4067, 8, 114, 5, 33, 222, 31, 55, 184, 704, 5586, 18020, 19, 346, 3153, 5, 6, 364, 350, 4, 184, 5586, 9, 133, 1810, 11, 5417, 13226, 21, 4, 7298, 42657, 570, 50, 2005, 2643, 9, 6, 1249, 17, 6, 25194, 27803, 21, 17, 6, 1211, 232, 1138, 2249, 29, 266, 56, 96, 346, 194, 308, 9, 194, 21, 29, 218, 1078, 19, 4, 78, 173, 7, 27, 20067, 5698, 3406, 718, 21264, 9, 6, 6907, 17, 210, 5, 3281, 5677, 47, 77, 395, 14, 172, 173, 18, 2740, 2931, 4517, 82, 127, 27, 173, 11, 6, 392, 217, 21, 50, 9, 57, 65, 12, 14274, 53, 40, 35, 390, 7, 11, 4, 3567, 7, 4, 314, 74, 6, 792, 22, 16261, 19, 714, 727, 5205, 382, 4, 91, 6533, 439, 19, 14, 20, 9, 1441, 5805, 1118, 4, 756, 25, 124, 4, 31, 12, 16, 93, 804, 34, 2005, 2643])],\n",
       "        dtype=object),\n",
       "  array([0, 1, 1, ..., 0, 0, 0], dtype=int64)))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use '1' as the character that indicates the start of a sequence\n",
    "imdb.load_data(start_char=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore the dataset word index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load the imdb word index using get_word_index()\n",
    "\n",
    "imdb_word_index = imdb.get_word_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the word index as a dictionary,\n",
    "# accounting for index_from.\n",
    "index_from = 3\n",
    "imdb_word_index = {key: value + index_from for key, value in imdb_word_index.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52256"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve a specific word's index\n",
    "imdb_word_index['simpsonian']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'film',\n",
       " 'was',\n",
       " 'just',\n",
       " 'brilliant',\n",
       " 'casting',\n",
       " 'location',\n",
       " 'scenery',\n",
       " 'story',\n",
       " 'direction',\n",
       " \"everyone's\",\n",
       " 'really',\n",
       " 'suited',\n",
       " 'the',\n",
       " 'part',\n",
       " 'they',\n",
       " 'played',\n",
       " 'and',\n",
       " 'you',\n",
       " 'could',\n",
       " 'just',\n",
       " 'imagine',\n",
       " 'being',\n",
       " 'there',\n",
       " 'robert',\n",
       " \"redford's\",\n",
       " 'is',\n",
       " 'an',\n",
       " 'amazing',\n",
       " 'actor',\n",
       " 'and',\n",
       " 'now',\n",
       " 'the',\n",
       " 'same',\n",
       " 'being',\n",
       " 'director',\n",
       " \"norman's\",\n",
       " 'father',\n",
       " 'came',\n",
       " 'from',\n",
       " 'the',\n",
       " 'same',\n",
       " 'scottish',\n",
       " 'island',\n",
       " 'as',\n",
       " 'myself',\n",
       " 'so',\n",
       " 'i',\n",
       " 'loved',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'there',\n",
       " 'was',\n",
       " 'a',\n",
       " 'real',\n",
       " 'connection',\n",
       " 'with',\n",
       " 'this',\n",
       " 'film',\n",
       " 'the',\n",
       " 'witty',\n",
       " 'remarks',\n",
       " 'throughout',\n",
       " 'the',\n",
       " 'film',\n",
       " 'were',\n",
       " 'great',\n",
       " 'it',\n",
       " 'was',\n",
       " 'just',\n",
       " 'brilliant',\n",
       " 'so',\n",
       " 'much',\n",
       " 'that',\n",
       " 'i',\n",
       " 'bought',\n",
       " 'the',\n",
       " 'film',\n",
       " 'as',\n",
       " 'soon',\n",
       " 'as',\n",
       " 'it',\n",
       " 'was',\n",
       " 'released',\n",
       " 'for',\n",
       " 'retail',\n",
       " 'and',\n",
       " 'would',\n",
       " 'recommend',\n",
       " 'it',\n",
       " 'to',\n",
       " 'everyone',\n",
       " 'to',\n",
       " 'watch',\n",
       " 'and',\n",
       " 'the',\n",
       " 'fly',\n",
       " 'fishing',\n",
       " 'was',\n",
       " 'amazing',\n",
       " 'really',\n",
       " 'cried',\n",
       " 'at',\n",
       " 'the',\n",
       " 'end',\n",
       " 'it',\n",
       " 'was',\n",
       " 'so',\n",
       " 'sad',\n",
       " 'and',\n",
       " 'you',\n",
       " 'know',\n",
       " 'what',\n",
       " 'they',\n",
       " 'say',\n",
       " 'if',\n",
       " 'you',\n",
       " 'cry',\n",
       " 'at',\n",
       " 'a',\n",
       " 'film',\n",
       " 'it',\n",
       " 'must',\n",
       " 'have',\n",
       " 'been',\n",
       " 'good',\n",
       " 'and',\n",
       " 'this',\n",
       " 'definitely',\n",
       " 'was',\n",
       " 'also',\n",
       " 'congratulations',\n",
       " 'to',\n",
       " 'the',\n",
       " 'two',\n",
       " 'little',\n",
       " \"boy's\",\n",
       " 'that',\n",
       " 'played',\n",
       " 'the',\n",
       " \"part's\",\n",
       " 'of',\n",
       " 'norman',\n",
       " 'and',\n",
       " 'paul',\n",
       " 'they',\n",
       " 'were',\n",
       " 'just',\n",
       " 'brilliant',\n",
       " 'children',\n",
       " 'are',\n",
       " 'often',\n",
       " 'left',\n",
       " 'out',\n",
       " 'of',\n",
       " 'the',\n",
       " 'praising',\n",
       " 'list',\n",
       " 'i',\n",
       " 'think',\n",
       " 'because',\n",
       " 'the',\n",
       " 'stars',\n",
       " 'that',\n",
       " 'play',\n",
       " 'them',\n",
       " 'all',\n",
       " 'grown',\n",
       " 'up',\n",
       " 'are',\n",
       " 'such',\n",
       " 'a',\n",
       " 'big',\n",
       " 'profile',\n",
       " 'for',\n",
       " 'the',\n",
       " 'whole',\n",
       " 'film',\n",
       " 'but',\n",
       " 'these',\n",
       " 'children',\n",
       " 'are',\n",
       " 'amazing',\n",
       " 'and',\n",
       " 'should',\n",
       " 'be',\n",
       " 'praised',\n",
       " 'for',\n",
       " 'what',\n",
       " 'they',\n",
       " 'have',\n",
       " 'done',\n",
       " \"don't\",\n",
       " 'you',\n",
       " 'think',\n",
       " 'the',\n",
       " 'whole',\n",
       " 'story',\n",
       " 'was',\n",
       " 'so',\n",
       " 'lovely',\n",
       " 'because',\n",
       " 'it',\n",
       " 'was',\n",
       " 'true',\n",
       " 'and',\n",
       " 'was',\n",
       " \"someone's\",\n",
       " 'life',\n",
       " 'after',\n",
       " 'all',\n",
       " 'that',\n",
       " 'was',\n",
       " 'shared',\n",
       " 'with',\n",
       " 'us',\n",
       " 'all']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View an input sentence\n",
    "\n",
    "print(imdb_word_index['the'])\n",
    "\n",
    "inv_imdb_word_index = {value: key for key, value in imdb_word_index.items()}\n",
    "[inv_imdb_word_index[index] for index in x_train[0] if index > index_from]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the sentiment value\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"coding_tutorial_2\"></a>\n",
    "## Padding and Masking Sequence Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the imdb data set\n",
    "\n",
    "import tensorflow.keras.datasets.imdb as imdb\n",
    "(x_train, y_train),(x_test,y_test) = imdb.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess the data with padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n",
      "(25000,)\n",
      "(25000,)\n",
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "# Inspect the input data shape\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the inputs to the maximum length using maxlen\n",
    "\n",
    "padded_x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=300, padding='post', \n",
    "                                                               truncating='pre')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 300)\n",
      "[    1    14    22    16    43   530   973  1622  1385    65   458  4468\n",
      "    66  3941     4   173    36   256     5    25   100    43   838   112\n",
      "    50   670 22665     9    35   480   284     5   150     4   172   112\n",
      "   167 21631   336   385    39     4   172  4536  1111    17   546    38\n",
      "    13   447     4   192    50    16     6   147  2025    19    14    22\n",
      "     4  1920  4613   469     4    22    71    87    12    16    43   530\n",
      "    38    76    15    13  1247     4    22    17   515    17    12    16\n",
      "   626    18 19193     5    62   386    12     8   316     8   106     5\n",
      "     4  2223  5244    16   480    66  3785    33     4   130    12    16\n",
      "    38   619     5    25   124    51    36   135    48    25  1415    33\n",
      "     6    22    12   215    28    77    52     5    14   407    16    82\n",
      " 10311     8     4   107   117  5952    15   256     4 31050     7  3766\n",
      "     5   723    36    71    43   530   476    26   400   317    46     7\n",
      "     4 12118  1029    13   104    88     4   381    15   297    98    32\n",
      "  2071    56    26   141     6   194  7486    18     4   226    22    21\n",
      "   134   476    26   480     5   144    30  5535    18    51    36    28\n",
      "   224    92    25   104     4   226    65    16    38  1334    88    12\n",
      "    16   283     5    16  4472   113   103    32    15    16  5345    19\n",
      "   178    32     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0]\n"
     ]
    }
   ],
   "source": [
    "# Inspect the output data shape\n",
    "print(padded_x_train.shape)\n",
    "print(padded_x_train[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Masking layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy \n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 300, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "# Masking expects to see (batch, sequence, features)\n",
    "# Create a dummy feature dimension using expand_dims\n",
    "\n",
    "padded_x_train = np.expand_dims(padded_x_train,-1)\n",
    "print(padded_x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Masking layer \n",
    "\n",
    "tf_x_train = tf.convert_to_tensor(padded_x_train, dtype='float32')\n",
    "masking_layer = tf.keras.layers.Masking(mask_value=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass tf_x_train to it\n",
    "masked_x_train = masking_layer(tf_x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[1.000e+00]]\n",
      "\n",
      "  [[1.400e+01]]\n",
      "\n",
      "  [[2.200e+01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.000e+00]]\n",
      "\n",
      "  [[0.000e+00]]\n",
      "\n",
      "  [[0.000e+00]]]\n",
      "\n",
      "\n",
      " [[[1.000e+00]]\n",
      "\n",
      "  [[1.940e+02]]\n",
      "\n",
      "  [[1.153e+03]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.000e+00]]\n",
      "\n",
      "  [[0.000e+00]]\n",
      "\n",
      "  [[0.000e+00]]]\n",
      "\n",
      "\n",
      " [[[1.000e+00]]\n",
      "\n",
      "  [[1.400e+01]]\n",
      "\n",
      "  [[4.700e+01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.000e+00]]\n",
      "\n",
      "  [[0.000e+00]]\n",
      "\n",
      "  [[0.000e+00]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[1.000e+00]]\n",
      "\n",
      "  [[1.100e+01]]\n",
      "\n",
      "  [[6.000e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.000e+00]]\n",
      "\n",
      "  [[0.000e+00]]\n",
      "\n",
      "  [[0.000e+00]]]\n",
      "\n",
      "\n",
      " [[[1.000e+00]]\n",
      "\n",
      "  [[1.446e+03]]\n",
      "\n",
      "  [[7.079e+03]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.000e+00]]\n",
      "\n",
      "  [[0.000e+00]]\n",
      "\n",
      "  [[0.000e+00]]]\n",
      "\n",
      "\n",
      " [[[1.000e+00]]\n",
      "\n",
      "  [[1.700e+01]]\n",
      "\n",
      "  [[6.000e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.000e+00]]\n",
      "\n",
      "  [[0.000e+00]]\n",
      "\n",
      "  [[0.000e+00]]]], shape=(25000, 300, 1, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[1.000e+00]]\n",
      "\n",
      "  [[1.400e+01]]\n",
      "\n",
      "  [[2.200e+01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.000e+00]]\n",
      "\n",
      "  [[0.000e+00]]\n",
      "\n",
      "  [[0.000e+00]]]\n",
      "\n",
      "\n",
      " [[[1.000e+00]]\n",
      "\n",
      "  [[1.940e+02]]\n",
      "\n",
      "  [[1.153e+03]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.000e+00]]\n",
      "\n",
      "  [[0.000e+00]]\n",
      "\n",
      "  [[0.000e+00]]]\n",
      "\n",
      "\n",
      " [[[1.000e+00]]\n",
      "\n",
      "  [[1.400e+01]]\n",
      "\n",
      "  [[4.700e+01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.000e+00]]\n",
      "\n",
      "  [[0.000e+00]]\n",
      "\n",
      "  [[0.000e+00]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[1.000e+00]]\n",
      "\n",
      "  [[1.100e+01]]\n",
      "\n",
      "  [[6.000e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.000e+00]]\n",
      "\n",
      "  [[0.000e+00]]\n",
      "\n",
      "  [[0.000e+00]]]\n",
      "\n",
      "\n",
      " [[[1.000e+00]]\n",
      "\n",
      "  [[1.446e+03]]\n",
      "\n",
      "  [[7.079e+03]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.000e+00]]\n",
      "\n",
      "  [[0.000e+00]]\n",
      "\n",
      "  [[0.000e+00]]]\n",
      "\n",
      "\n",
      " [[[1.000e+00]]\n",
      "\n",
      "  [[1.700e+01]]\n",
      "\n",
      "  [[6.000e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.000e+00]]\n",
      "\n",
      "  [[0.000e+00]]\n",
      "\n",
      "  [[0.000e+00]]]], shape=(25000, 300, 1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Look at the dataset\n",
    "\n",
    "print(tf_x_train)\n",
    "print(masked_x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ True]\n",
      "  [ True]\n",
      "  [ True]\n",
      "  ...\n",
      "  [False]\n",
      "  [False]\n",
      "  [False]]\n",
      "\n",
      " [[ True]\n",
      "  [ True]\n",
      "  [ True]\n",
      "  ...\n",
      "  [False]\n",
      "  [False]\n",
      "  [False]]\n",
      "\n",
      " [[ True]\n",
      "  [ True]\n",
      "  [ True]\n",
      "  ...\n",
      "  [False]\n",
      "  [False]\n",
      "  [False]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ True]\n",
      "  [ True]\n",
      "  [ True]\n",
      "  ...\n",
      "  [False]\n",
      "  [False]\n",
      "  [False]]\n",
      "\n",
      " [[ True]\n",
      "  [ True]\n",
      "  [ True]\n",
      "  ...\n",
      "  [False]\n",
      "  [False]\n",
      "  [False]]\n",
      "\n",
      " [[ True]\n",
      "  [ True]\n",
      "  [ True]\n",
      "  ...\n",
      "  [False]\n",
      "  [False]\n",
      "  [False]]], shape=(25000, 300, 1), dtype=bool)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tensorflow.python.framework.ops.EagerTensor' object has no attribute '_keras_mask'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-98a755f40c79>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Look at the ._keras_mask for the dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmasked_x_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keras_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf_x_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keras_mask\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# this will fail\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute '_keras_mask'"
     ]
    }
   ],
   "source": [
    "# Look at the ._keras_mask for the dataset\n",
    "print(masked_x_train._keras_mask)\n",
    "print(tf_x_train._keras_mask) # this will fail\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_3\"></a>\n",
    "## The Embedding layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and apply an `Embedding` layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an embedding layer using layers.Embedding\n",
    "# Specify input_dim, output_dim, input_length\n",
    "\n",
    "embedding_layer = tf.keras.layers.Embedding(input_dim=501, output_dim=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1, 16)\n",
      "tf.Tensor(\n",
      "[[[-0.00770904  0.04692097  0.02012486 -0.03399613 -0.03189063\n",
      "    0.00940977  0.04772184 -0.02070488  0.03035805  0.01830271\n",
      "    0.04818766  0.01372326  0.00425174  0.04064311  0.02398472\n",
      "   -0.04474435]]\n",
      "\n",
      " [[-0.00173507 -0.0499667  -0.03594355  0.03792052 -0.02940575\n",
      "    0.01796051  0.02368579  0.04256989 -0.01066665 -0.011508\n",
      "   -0.01217892 -0.03625873  0.01563143  0.00571803  0.04900717\n",
      "   -0.00552535]]\n",
      "\n",
      " [[-0.02754815 -0.03537084 -0.03953522 -0.0009303   0.03039023\n",
      "   -0.03321102  0.00367044  0.00595316 -0.02675568 -0.03168929\n",
      "    0.0141421   0.02399227  0.04789884 -0.01842116  0.01245034\n",
      "    0.00692701]]\n",
      "\n",
      " [[-0.00152105 -0.0447723  -0.0497669  -0.01042248 -0.0222538\n",
      "    0.00045408  0.03809645 -0.03171574  0.04175514 -0.01133571\n",
      "    0.03368345  0.01083151 -0.0184445  -0.04664895  0.00897645\n",
      "   -0.00527821]]], shape=(4, 1, 16), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Inspect an Embedding layer output for a fixed input\n",
    "# Expects an input of shape (batch, sequence, feature)\n",
    "\n",
    "sequence_of_indices = tf.constant((([0],[1],[5],[500])))\n",
    "#shape of sequence of indices (batch, sequence, features)\n",
    "sequence_of_embeddings = embedding_layer(sequence_of_indices)\n",
    "print(sequence_of_embeddings.shape)\n",
    "print(sequence_of_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.00770904,  0.04692097,  0.02012486, ...,  0.04064311,\n",
      "         0.02398472, -0.04474435],\n",
      "       [-0.00173507, -0.0499667 , -0.03594355, ...,  0.00571803,\n",
      "         0.04900717, -0.00552535],\n",
      "       [ 0.02355262,  0.00674796,  0.01960503, ..., -0.00382177,\n",
      "         0.02089684, -0.0318689 ],\n",
      "       ...,\n",
      "       [-0.01885115, -0.0104336 , -0.0147663 , ..., -0.03072448,\n",
      "        -0.04596573, -0.03066056],\n",
      "       [-0.02056266, -0.03235048,  0.02405715, ...,  0.0014303 ,\n",
      "         0.02917844, -0.01145347],\n",
      "       [-0.00152105, -0.0447723 , -0.0497669 , ..., -0.04664895,\n",
      "         0.00897645, -0.00527821]], dtype=float32)]\n",
      "(1, 501, 16)\n"
     ]
    }
   ],
   "source": [
    "# Inspect the Embedding layer weights using get_weights()\n",
    "\n",
    "weights = embedding_layer.get_weights()\n",
    "print(weights)\n",
    "print(np.array(weights).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03693639,  0.04711595, -0.03755499,  0.0009927 , -0.0263589 ,\n",
       "        0.01670611, -0.00097736,  0.02822841,  0.03103436,  0.04271455,\n",
       "       -0.00865202,  0.00083437, -0.00951665, -0.02701598, -0.04016546,\n",
       "       -0.0004255 ], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the embedding for the 14th index\n",
    "\n",
    "embedding_layer.get_weights()[0][14,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and apply an `Embedding` layer that uses `mask_zero=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a layer that uses the mask_zero kwarg\n",
    "\n",
    "masking_embedding_layer = tf.keras.layers.Embedding(input_dim=501, output_dim=16, mask_zero=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 1), dtype=bool, numpy=\n",
       "array([[False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply this layer to the sequence and see the _keras_mask property\n",
    "\n",
    "masked_sequence_of_embeddings = masking_embedding_layer(sequence_of_indices )\n",
    "masked_sequence_of_embeddings._keras_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"coding_tutorial_4\"></a>\n",
    "## The Embedding Projector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and preprocess the IMDb data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to load and preprocess the IMDB dataset\n",
    "\n",
    "def get_and_pad_imdb_dataset(num_words=10000, maxlen=None, index_from=2):\n",
    "    from tensorflow.keras.datasets import imdb\n",
    "\n",
    "    # Load the reviews\n",
    "    (x_train, y_train), (x_test, y_test) = imdb.load_data(path='imdb.npz',\n",
    "                                                          num_words=num_words,\n",
    "                                                          skip_top=0,\n",
    "                                                          maxlen=maxlen,\n",
    "                                                          start_char=1,\n",
    "                                                          oov_char=2,\n",
    "                                                          index_from=index_from)\n",
    "\n",
    "    x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        maxlen=None,\n",
    "                                                        padding='pre',\n",
    "                                                        truncating='pre',\n",
    "                                                        value=0)\n",
    "    \n",
    "    x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                           maxlen=None,\n",
    "                                                           padding='pre',\n",
    "                                                           truncating='pre',\n",
    "                                                           value=0)\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "(x_train, y_train),(x_test, y_test) = get_and_pad_imdb_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to get the dataset word index\n",
    "\n",
    "def get_imdb_word_index(num_words=10000, index_from=2):\n",
    "    imdb_word_index = tf.keras.datasets.imdb.get_word_index(\n",
    "                                        path='imdb_word_index.json')\n",
    "    imdb_word_index = {key: value + index_from for\n",
    "                       key, value in imdb_word_index.items() if value <= num_words-index_from}\n",
    "    return imdb_word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the word index\n",
    "\n",
    "imdb_word_index = get_imdb_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap the keys and values of the word index\n",
    "\n",
    "inv_imdb_word_index={value: key for key, value in imdb_word_index.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'10',\n",
       " '2',\n",
       " 'a',\n",
       " 'about',\n",
       " 'all',\n",
       " 'am',\n",
       " 'and',\n",
       " 'are',\n",
       " 'as',\n",
       " 'because',\n",
       " 'been',\n",
       " 'black',\n",
       " 'box',\n",
       " 'bucks',\n",
       " 'bunch',\n",
       " 'but',\n",
       " 'care',\n",
       " 'cartoons',\n",
       " 'clear',\n",
       " 'crap',\n",
       " 'curiosity',\n",
       " 'david',\n",
       " \"didn't\",\n",
       " 'disappointing',\n",
       " \"don't\",\n",
       " 'drawn',\n",
       " 'dvd',\n",
       " 'everything',\n",
       " 'except',\n",
       " 'fan',\n",
       " 'few',\n",
       " 'for',\n",
       " 'foul',\n",
       " 'found',\n",
       " 'good',\n",
       " 'grabbed',\n",
       " 'great',\n",
       " 'had',\n",
       " 'have',\n",
       " \"he's\",\n",
       " 'highly',\n",
       " 'hotel',\n",
       " 'hour',\n",
       " 'i',\n",
       " 'immediately',\n",
       " 'in',\n",
       " 'is',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'just',\n",
       " 'keep',\n",
       " 'know',\n",
       " 'language',\n",
       " 'left',\n",
       " 'let',\n",
       " 'loud',\n",
       " 'lynch',\n",
       " 'made',\n",
       " 'make',\n",
       " 'may',\n",
       " 'maybe',\n",
       " 'me',\n",
       " 'might',\n",
       " 'money',\n",
       " 'mouthed',\n",
       " 'movie',\n",
       " 'my',\n",
       " 'name',\n",
       " 'neighbors',\n",
       " 'of',\n",
       " 'on',\n",
       " 'out',\n",
       " 'part',\n",
       " 'peaks',\n",
       " 'public',\n",
       " 'recommend',\n",
       " 'release',\n",
       " 'room',\n",
       " 'set',\n",
       " 'so',\n",
       " 'sound',\n",
       " 'spend',\n",
       " 'that',\n",
       " 'the',\n",
       " 'this',\n",
       " 'to',\n",
       " 'too',\n",
       " 'twin',\n",
       " 'under',\n",
       " 'unfunny',\n",
       " 'was',\n",
       " 'well',\n",
       " 'what',\n",
       " \"what's\",\n",
       " 'when',\n",
       " 'white',\n",
       " 'you',\n",
       " 'your'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the first dataset example sentence\n",
    "\n",
    "{inv_imdb_word_index[index] for index in x_train[100] if index  > 2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build an Embedding layer into a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the maximum token value\n",
    "\n",
    "max_index_value = max(imdb_word_index.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify an embedding dimension\n",
    "\n",
    "embedding_dim = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a model using Sequential:\n",
    "#     1. Embedding layer\n",
    "#     2. GlobalAveragePooling1D\n",
    "#     3. Dense\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "                            tf.keras.layers.Embedding(input_dim=max_index_value+1, output_dim=embedding_dim, mask_zero=False),\n",
    "                            tf.keras.layers.GlobalAveragePooling1D(),\n",
    "                            tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functional API refresher: use the Model to build the same model\n",
    "\n",
    "review_sequence = tf.keras.Input((None,))\n",
    "embedding_sequence = tf.keras.layers.Embedding(input_dim=max_index_value+1, output_dim=embedding_dim, mask_zero=False)(review_sequence)\n",
    "average_embedding = tf.keras.layers.GlobalAveragePooling1D()(embedding_sequence)\n",
    "positive_probability = tf.keras.layers.Dense(units=1, activation='sigmoid')(average_embedding)\n",
    "\n",
    "model = tf.keras.Model(inputs=review_sequence, outputs=positive_probability)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_8 (Embedding)      (None, None, 16)          160016    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 160,033\n",
      "Trainable params: 160,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile, train, and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with a binary cross-entropy loss\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', metrics=['accuracy'], optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 18s 711us/sample - loss: 0.6900 - accuracy: 0.5426 - val_loss: 0.0175 - val_accuracy: 0.6281\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 17s 698us/sample - loss: 0.6708 - accuracy: 0.6940 - val_loss: 0.0167 - val_accuracy: 0.7469\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 17s 684us/sample - loss: 0.6293 - accuracy: 0.7583 - val_loss: 0.0155 - val_accuracy: 0.7672\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 17s 687us/sample - loss: 0.5789 - accuracy: 0.7922 - val_loss: 0.0142 - val_accuracy: 0.7859\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 17s 682us/sample - loss: 0.5307 - accuracy: 0.8168 - val_loss: 0.0131 - val_accuracy: 0.8000\n"
     ]
    }
   ],
   "source": [
    "# Train the model using .fit(), savng its history\n",
    "history = model.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_test, y_test), validation_steps=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training and validation accuracy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "history_dict = history.history\n",
    "\n",
    "acc      = history_dict['accuracy']\n",
    "val_acc  = history_dict['val_accuracy']\n",
    "loss     = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.plot(epochs, acc, marker='.', label='Training acc')\n",
    "plt.plot(epochs, val_acc, marker='.', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Classification accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim(0, 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The TensorFlow embedding projector\n",
    "\n",
    "The Tensorflow embedding projector can be found [here](https://projector.tensorflow.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the embedding layer's weights from the trained model\n",
    "\n",
    "weights = model.layers[1].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the word Embeddings to tsv files\n",
    "# Two files: \n",
    "#     one contains the embedding labels (meta.tsv),\n",
    "#     one contains the embeddings (vecs.tsv)\n",
    "\n",
    "import io\n",
    "from os import path\n",
    "\n",
    "out_v = io.open(path.join('data', 'vecs.tsv'), 'w', encoding='utf-8')\n",
    "out_m = io.open(path.join('data', 'meta.tsv'), 'w', encoding='utf-8')\n",
    "\n",
    "k = 0\n",
    "\n",
    "for word, token in imdb_word_index.items():\n",
    "    if k != 0:\n",
    "        out_m.write('\\n')\n",
    "        out_v.write('\\n')\n",
    "    \n",
    "    out_v.write('\\t'.join([str(x) for x in weights[token]]))\n",
    "    out_m.write(word)\n",
    "    k += 1\n",
    "    \n",
    "out_v.close()\n",
    "out_m.close()\n",
    "# beware large collections of embeddings!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"coding_tutorial_5\"></a>\n",
    "## Recurrent neural network layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize and pass an input to a SimpleRNN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SimpleRNN layer and test it\n",
    "\n",
    "#SimpleRNN, LSTM, GRU All these expect input in this format batch, sequence, features\n",
    "\n",
    "simplernn_layer = tf.keras.layers.SimpleRNN(units=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-1.          1.          1.          1.          1.          1.\n",
      "  -1.         -0.99999994 -1.          0.99862576 -1.         -1.\n",
      "   1.          1.          1.         -1.        ]], shape=(1, 16), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Note that only the final cell output is returned\n",
    "\n",
    "sequence = tf.constant([[[1.,1.],[2.,2.],[56.,-100]]])\n",
    "layer_output = simplernn_layer(sequence)\n",
    "print(layer_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and transform the IMDB review sentiment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to load and preprocess the IMDB dataset\n",
    "\n",
    "def get_and_pad_imdb_dataset(num_words=10000, maxlen=None, index_from=2):\n",
    "    from tensorflow.keras.datasets import imdb\n",
    "\n",
    "    # Load the reviews\n",
    "    (x_train, y_train), (x_test, y_test) = imdb.load_data(path='imdb.npz',\n",
    "                                                          num_words=num_words,\n",
    "                                                          skip_top=0,\n",
    "                                                          maxlen=maxlen,\n",
    "                                                          start_char=1,\n",
    "                                                          oov_char=2,\n",
    "                                                          index_from=index_from)\n",
    "\n",
    "    x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        maxlen=None,\n",
    "                                                        padding='pre',\n",
    "                                                        truncating='pre',\n",
    "                                                        value=0)\n",
    "    \n",
    "    x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                           maxlen=None,\n",
    "                                                           padding='pre',\n",
    "                                                           truncating='pre',\n",
    "                                                           value=0)\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "(x_train, y_train),(x_test,y_test) = get_and_pad_imdb_dataset(maxlen=250)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to get the dataset word index\n",
    "\n",
    "def get_imdb_word_index(num_words=10000, index_from=2):\n",
    "    imdb_word_index = tf.keras.datasets.imdb.get_word_index(\n",
    "                                        path='imdb_word_index.json')\n",
    "    imdb_word_index = {key: value + index_from for\n",
    "                       key, value in imdb_word_index.items() if value <= num_words-index_from}\n",
    "    return imdb_word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the word index using get_imdb_word_index()\n",
    "\n",
    "imdb_word_index = get_imdb_word_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a recurrent neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the maximum index value\n",
    "max_index_value = max(imdb_word_index.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Sequential, build the model:\n",
    "# 1. Embedding.\n",
    "# 2. LSTM.\n",
    "# 3. Dense.\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim = max_index_value+1, output_dim = embedding_dim, mask_zero = True),\n",
    "    tf.keras.layers.LSTM(units=16),\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with binary cross-entropy loss\n",
    "model.compile(loss = 'binary_crossentropy', metrics=['accuracy'], optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 254s 10ms/sample - loss: 0.4008 - accuracy: 0.8178\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 247s 10ms/sample - loss: 0.2263 - accuracy: 0.9130\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 245s 10ms/sample - loss: 0.1812 - accuracy: 0.9334\n"
     ]
    }
   ],
   "source": [
    "# Fit the model and save its training history\n",
    "history = model.fit(x_train,y_train,epochs=3, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-109-3b8680024394>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0macc\u001b[0m      \u001b[1;33m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mval_acc\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mloss\u001b[0m     \u001b[1;33m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'val_accuracy'"
     ]
    }
   ],
   "source": [
    "# Plot the training and validation accuracy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "history_dict = history.history\n",
    "\n",
    "acc      = history_dict['accuracy']\n",
    "val_acc  = history_dict['val_accuracy']\n",
    "loss     = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.plot(epochs, acc, marker='.', label='Training acc')\n",
    "plt.plot(epochs, val_acc, marker='.', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Classification accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim(0, 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make predictions with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'10',\n",
       " '8',\n",
       " \"80's\",\n",
       " 'a',\n",
       " 'almost',\n",
       " 'and',\n",
       " 'awesome',\n",
       " 'bad',\n",
       " 'be',\n",
       " 'because',\n",
       " 'before',\n",
       " 'best',\n",
       " 'blood',\n",
       " 'br',\n",
       " 'budget',\n",
       " 'can',\n",
       " 'cool',\n",
       " 'creepiness',\n",
       " 'crew',\n",
       " 'dawn',\n",
       " 'decent',\n",
       " 'dedicated',\n",
       " \"doesn't\",\n",
       " 'done',\n",
       " 'early',\n",
       " 'enjoyed',\n",
       " 'everything',\n",
       " 'example',\n",
       " 'fierce',\n",
       " 'film',\n",
       " 'for',\n",
       " 'freaked',\n",
       " 'fun',\n",
       " 'girlfriend',\n",
       " 'got',\n",
       " 'great',\n",
       " 'have',\n",
       " 'hell',\n",
       " 'here',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'idea',\n",
       " 'if',\n",
       " 'ignore',\n",
       " 'in',\n",
       " 'is',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'just',\n",
       " 'kids',\n",
       " 'killer',\n",
       " 'lot',\n",
       " 'me',\n",
       " 'minimal',\n",
       " 'more',\n",
       " 'most',\n",
       " 'movie',\n",
       " 'my',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'other',\n",
       " 'out',\n",
       " 'plenty',\n",
       " 'really',\n",
       " 'reviews',\n",
       " 'ripped',\n",
       " 'say',\n",
       " 'scares',\n",
       " 'script',\n",
       " 'she',\n",
       " 'slasher',\n",
       " 'slashers',\n",
       " 'so',\n",
       " 'something',\n",
       " 'than',\n",
       " 'that',\n",
       " 'the',\n",
       " 'there',\n",
       " \"there's\",\n",
       " 'this',\n",
       " 'to',\n",
       " 'turn',\n",
       " 'unique',\n",
       " 'was',\n",
       " 'watches',\n",
       " 'what',\n",
       " 'with',\n",
       " 'wrong',\n",
       " 'you'}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the first test data example sentence\n",
    "# (invert the word index)\n",
    "\n",
    "inv_imdb_word_index = {value: key for key,value in imdb_word_index.items()}\n",
    "{inv_imdb_word_index[index] for index in x_test[0] if index>2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9943236]], dtype=float32)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the model prediction using model.predict()\n",
    "model.predict(x_test[None,0,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the corresponding label\n",
    "y_test[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"coding_tutorial_6\"></a>\n",
    "## Stacked RNNs and the Bidirectional wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and transform the IMDB review sentiment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to load and preprocess the IMDB dataset\n",
    "\n",
    "def get_and_pad_imdb_dataset(num_words=10000, maxlen=None, index_from=2):\n",
    "    from tensorflow.keras.datasets import imdb\n",
    "\n",
    "    # Load the reviews\n",
    "    (x_train, y_train), (x_test, y_test) = imdb.load_data(path='imdb.npz',\n",
    "                                                          num_words=num_words,\n",
    "                                                          skip_top=0,\n",
    "                                                          maxlen=maxlen,\n",
    "                                                          start_char=1,\n",
    "                                                          oov_char=2,\n",
    "                                                          index_from=index_from)\n",
    "\n",
    "    x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        maxlen=None,\n",
    "                                                        padding='pre',\n",
    "                                                        truncating='pre',\n",
    "                                                        value=0)\n",
    "    \n",
    "    x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                           maxlen=None,\n",
    "                                                           padding='pre',\n",
    "                                                           truncating='pre',\n",
    "                                                           value=0)\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "(x_train, y_train),(x_test,y_test) = get_and_pad_imdb_dataset(num_words=5000, maxlen=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to get the dataset word index\n",
    "\n",
    "def get_imdb_word_index(num_words=10000, index_from=2):\n",
    "    imdb_word_index = tf.keras.datasets.imdb.get_word_index(\n",
    "                                        path='imdb_word_index.json')\n",
    "    imdb_word_index = {key: value + index_from for\n",
    "                       key, value in imdb_word_index.items() if value <= num_words-index_from}\n",
    "    return imdb_word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the word index using get_imdb_word_index()\n",
    "\n",
    "\n",
    "imdb_word_index = get_imdb_word_index(num_words=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build stacked and bidirectional recurrent models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the maximum index value and specify an embedding dimension\n",
    "\n",
    "max_index_value = max(imdb_word_index.values())\n",
    "embedding_dim = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Sequential, build a stacked LSTM model via return_sequences=True\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=max_index_value+1, output_dim=embedding_dim, mask_zero=True),\n",
    "    tf.keras.layers.LSTM(units=32,  return_sequences=True),\n",
    "    tf.keras.layers.LSTM(units=32, return_sequences=False),\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Sequential, build a bidirectional RNN with merge_mode='sum'\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=max_index_value+1, output_dim=embedding_dim, mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(layer=tf.keras.layers.LSTM(units=8),merge_mode='sum',\n",
    "                                 backward_layer=tf.keras.layers.GRU(units=8, go_backwards=True)),\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model featuring both stacked recurrent layers and a bidirectional layer\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=max_index_value+1, output_dim=embedding_dim),\n",
    "    tf.keras.layers.Bidirectional(layer=tf.keras.layers.LSTM(units=8, return_sequences=True), merge_mode='concat'),\n",
    "    tf.keras.layers.GRU(units=8, return_sequences=False),\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "\n",
    "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 634s 25ms/sample - loss: 0.4090 - accuracy: 0.8066\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 617s 25ms/sample - loss: 0.2525 - accuracy: 0.9019\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 615s 25ms/sample - loss: 0.1988 - accuracy: 0.9249\n"
     ]
    }
   ],
   "source": [
    "# Train the model, saving its history\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=32, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-135-3b8680024394>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0macc\u001b[0m      \u001b[1;33m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mval_acc\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mloss\u001b[0m     \u001b[1;33m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'val_accuracy'"
     ]
    }
   ],
   "source": [
    "# Plot the training and validation accuracy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "history_dict = history.history\n",
    "\n",
    "acc      = history_dict['accuracy']\n",
    "val_acc  = history_dict['val_accuracy']\n",
    "loss     = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.plot(epochs, acc, marker='.', label='Training acc')\n",
    "plt.plot(epochs, val_acc, marker='.', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Classification accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim(0, 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
