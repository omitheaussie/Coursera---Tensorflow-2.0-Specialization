{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omkar.karve\\AppData\\Roaming\\Python\\Python37\\site-packages\\requests\\__init__.py:80: RequestsDependencyWarning: urllib3 (1.26.2) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tensorflow_probability.python.distributions' from 'C:\\\\Users\\\\omkar.karve\\\\.conda\\\\envs\\\\motion\\\\lib\\\\site-packages\\\\tensorflow_probability\\\\python\\\\distributions\\\\__init__.py'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = tfd.Normal(loc=0., scale=1.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([ 0.08000929, -1.5197878 , -0.6406692 ], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.35206532>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal.prob(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=-1.0439385>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal.log_prob(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0440237675087614"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.log(0.35203532)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfp.distributions.Bernoulli(\"Bernoulli\", batch_shape=[], event_shape=[], dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "bern = tfd.Bernoulli(logits=0.847)\n",
    "print(bern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 1, 1])>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bern.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.69993746>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bern.prob(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfp.distributions.Bernoulli(\"Bernoulli\", batch_shape=[2], event_shape=[], dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "batched_bern = tfd.Bernoulli(probs=[0.4,0.5])\n",
    "print(batched_bern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[0, 0],\n",
       "       [0, 0],\n",
       "       [0, 1]])>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_bern.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.4, 0.5], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_bern.prob([1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfp.distributions.MultivariateNormalDiag(\"MultivariateNormalDiag\", batch_shape=[], event_shape=[2], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "mv_normal = tfd.MultivariateNormalDiag(loc=[-1,0.5], scale_diag=[1.,1.5])\n",
    "print(mv_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mv_normal.event_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[-1.615947  , -1.3021022 ],\n",
       "       [ 0.32211852, -0.11452258],\n",
       "       [-1.4408972 ,  1.2506003 ]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mv_normal.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfp.distributions.Normal(\"Normal\", batch_shape=[2], event_shape=[], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "batched_normal = tfd.Normal(loc=[-1,0.5], scale=[1.,1.5])\n",
    "print(batched_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[-0.2397803 ,  2.5428483 ],\n",
       "       [ 0.85000706,  2.5582943 ],\n",
       "       [ 0.33503187,  1.3704139 ]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_normal.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batched Multivariate diag distribution is a normal distribution of 2 independent variables (event shape is 2)\n",
    "Hence 3 samples are showing probabilities of 2 independent events per sample - 3X2\n",
    "Whereas the normal batched sample is just two different probabilities of the same event with different values\n",
    "Event shape of a normal distribution is empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=-2.9388978>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mv_normal.log_prob([-0.2, 1.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([-1.2389386, -1.699959 ], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_normal.log_prob([-.2, 1.8])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When log prob is calculated for a multivariate distribution that is passed a 1x2 array, it calculates \n",
    "log probability of one instance of getting the 1X2 random variable hence log prob is a single value \n",
    "Whereas log prob of a univariate normal distribution that is passed a 1x2 array outputs\n",
    "two different log probabilits of two different instances within that single distribution hence the \n",
    "output is a 1x2 array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_mv_normal = tfd.MultivariateNormalDiag(\n",
    "                    loc=[[-1.,0.5],[2.,0.],[-0.5,1.5]],\n",
    "                    scale_diag=[[1.,1.5],[2.,0.5],[1.,1.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfp.distributions.MultivariateNormalDiag(\"MultivariateNormalDiag\", batch_shape=[3], event_shape=[2], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(batched_mv_normal)\n",
    "# Here loc is a 3x2 array, there are 3 batches and each batch contains one instance of a 2D random variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3, 2), dtype=float32, numpy=\n",
       "array([[[-2.7421708 , -0.4984879 ],\n",
       "        [ 1.1081645 , -0.12068057],\n",
       "        [-2.2804341 ,  1.2456772 ]],\n",
       "\n",
       "       [[-1.2511964 ,  0.73182046],\n",
       "        [ 1.1839368 , -0.9681898 ],\n",
       "        [-1.0132573 , -0.8188286 ]],\n",
       "\n",
       "       [[-0.27510667,  0.21074677],\n",
       "        [ 2.383969  , -0.47781435],\n",
       "        [-1.5911664 ,  1.9778253 ]],\n",
       "\n",
       "       [[-1.0960193 ,  1.4839597 ],\n",
       "        [ 3.4861307 , -0.33728957],\n",
       "        [-2.7676692 ,  1.9263558 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_mv_normal.sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_mv_normal = tfd.MultivariateNormalDiag(\n",
    "    loc=[[0.3, 0.8, 1.1], [2.3, -0.3, -1.]], \n",
    "    scale_diag=[[1.5, 1., 0.4], [2.5, 1.5, 0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfp.distributions.MultivariateNormalDiag(\"MultivariateNormalDiag\", batch_shape=[2], event_shape=[3], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(batched_mv_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([ -3.9172401, -11.917513 ], dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_mv_normal.log_prob([0., -1., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[-5.9249983, -5.6765656],\n",
       "       [-3.9769206, -5.1262293]], dtype=float32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_mv_normal.log_prob(batched_mv_normal.sample(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batched_normal_multivariate sample size => samplesize x batchsize x eventsize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Independent distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfp.distributions.Independent(\"IndependentNormal\", batch_shape=[], event_shape=[2], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "batched_norm = tfd.Normal(loc=[-1., 0.5], scale=[1., 1.5])\n",
    "\n",
    "independent_norm = tfd.Independent(batched_norm, reinterpreted_batch_ndims=1)\n",
    "print(independent_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([-1.2389386, -1.699959 ], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_norm.log_prob([-0.2,1.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=-2.9388976>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "independent_norm.log_prob([-0.2,1.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfp.distributions.Normal(\"Normal\", batch_shape=[3, 2], event_shape=[], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "batched_norm = tfd.Normal(\n",
    "                           loc=[[-1,0.5],[0.,1.],[0.3,-0.1]],\n",
    "                           scale=[[1.,1.5],[0.2,0.8],[2.,1.]] )\n",
    "print(batched_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfp.distributions.Independent(\"IndependentNormal\", batch_shape=[3], event_shape=[2], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "independent_norm = tfd.Independent(batched_norm, reinterpreted_batch_ndims=1)\n",
    "print(independent_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfp.distributions.Independent(\"IndependentNormal\", batch_shape=[], event_shape=[3, 2], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "independent_norm = tfd.Independent(batched_norm, reinterpreted_batch_ndims=2)\n",
    "print(independent_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainable distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal = tfd.Normal(loc=0.,scale=1.)\n",
    "normal.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'loc:0' shape=() dtype=float32, numpy=0.0>,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal = tfd.Normal(loc=tf.Variable(0.,name='loc'),scale=1.)\n",
    "normal.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning principle is maximum likelihood. Finding parameters that maximize the likelihood is the same as finding params\n",
    "# that minimize the negative log likelihood.\n",
    "# reason we are using reduce_mean instead of sum is to prevent the loss scaling with the size of the data\n",
    "# this doesnt change the optimium solution\n",
    "def nll(x_train):\n",
    "    return -tf.reduce_mean(normal.log_prob(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def get_loss_and_grads(x_train):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(normal.trainable_variables)\n",
    "        loss = nll(x_train)\n",
    "    grads = tape.gradient(loss,normal.trainable_variables) #this is where the heav computation happens\n",
    "    return loss, grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_samples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-9f3e45d88d0d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mnum_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m \u001b[1;31m#some random value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_loss_and_grads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_samples' is not defined"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.05)\n",
    "num_steps=100 #some random value\n",
    "for _ in range(num_steps):\n",
    "    loss,grads = get_loss_and_grads(x_samples)\n",
    "    optimizer.apply_gradients(zip(grads,normal.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
